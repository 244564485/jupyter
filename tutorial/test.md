# 软件测试

软件测试的对象
程序、数据、文档，跟人没有关系
 
测试用例
要设计有效的功能测试用例，应该做到
1、测试用例应该100%地覆盖测试业务需求
2、利用场景法模拟核心业务流程的正确执行
3、利用场景法设计测试用例时，往往是一个业务流程需要多条验证数据
4、利用边界值法设计测试用例，能够验证输入值的便捷处理是否正确
 
决策表（判定表）测试用例设计步骤
1、依据软件规格说明：确定规则个数
2、列出所有的条件状和动作桩
3、输入条件项
4、输入动作项，制定初始判定表
5、合并相似规则
 
场景法设计测试用例步骤
1、根据规格说明，描述出程序的基本流及各项备选流
2、根据基本流和备选流确定场景
3、对每一个场景生成相应的测试用例，可以采用矩阵或决策表来确定和管理测试用例
4、对生成的测试用例进行复审，去掉多余或等价的测试用例，然后确定实际测试数据
 
链接测试，需要测试哪些方面？
1、内部链接，外向链接，发送Email，页面中链接跳转，断链（主要分为内外部、断链）
2、链接的页面是否存在
3、点击链接是否能跳转到对应页面
4、是否存在孤立页面，即只有通过特定URL才能访问到的页面
 
图形测试主要测试点
1、颜色饱和度、对比度是否合适
2、需要突出的链接的颜色是否容易识别
3、是否正确加载所有图形
4、数据变化时，图形是否实时变化
5、不同数据类型，图形是否加以区分
 
页面测试主要方面
1、页面的一致性如何
2、每个页面上是否设计友好的用户界面和直观的导航系统
3、是否考虑多种浏览器
4、是否充分考虑了合适的页面布局技术，如css、表格结构
 
兼容性测试矩阵
需要测浏览器兼容性、操作系统兼容性、移动端浏览兼容性、打印测试、硬件兼容性、数据兼容性
 
表单测试的主要测试内容
1、字段验证
2、字段缺省值
3、输入验证
4、提交验证

对数据库中的数据的安全性、完整性、并发和故障恢复的控制
安全性：防止不合法的使用造成的数据泄露、破坏
完整性：防止向数据库加入不符合语义的数据
并发控制：导致数据不一致性，主要有：丢失更新、不可重复读和读脏数据，主要原因是破坏了事务的隔离性
故障恢复：有三类故障，事务内部故障、系统故障、介质故障



常见系统测试主要内容
1、恢复测试，测试系统容错能力
2、安全性测试
3、压力测试
4、性能测试
5、可靠性测试
6、安装测试
 
逻辑覆盖法
1、语句覆盖：每一条可执行语句
2、判定覆盖：每个判定至少有一次真，一次假
3、条件覆盖：每个判断的每个条件可能取值至少执行一次
4、判定/条件覆盖：每个判定的每个条件取得各种可能的结果
5、条件组合：使得每个判断的所有可能的条件取值组合至少执行一次，满足条件组合覆盖的测试用例一定满足判定覆盖、条件覆盖和判定/条件覆盖
 
软件质量模型特性
1、功能性
2、适合性
3、准确性
4、互操作性
5、安全性
6、依从性
 
因果图法
1、适用于必须描述多种条件的组合
2、需要转换成判定表，然后再设计测试用例
 
条件组合覆盖测试用例数
2^条件数
 
单元测试包含模块
接口测试，局部数据结构测试，路径测试，错误处理测试，边界测试
 
集成测试的集成方式
1、一次性集成
2、自底向上
3、自顶向下
4、混合式
5、Big-Bang
 
集成测试
1、需要设计所需的驱动模块和桩模块
2、驱动模块：相当于所测函数的主程序
3、桩模块：用来模拟被测模块工作过程中所调用的模块，它们只进行很少的数据处理
 
如何划分测试阶段
按开发阶段划分：单元测试、集成测试、系统测试、确认测试、验收测试
按测试技术划分：白盒测试、黑盒测试、灰盒测试
按实施组织划分：开发方测试、用户测试、第三方测试
 
MTTF
描述可靠性的指标 
 
标准复合型测试
1、数据内容标准
2、通信协议
3、开发接口
4、信息编码
 
文档测试
1、面向读者应该定位要明确，不能一个文档面向所有级别
2、检查软件返回结果跟文档描述是否一致属于一致性方面
 
场景测试法
基本流+备用流
 
测试停止准则
1、测试超过预定时间
2、执行完了所有用例没有发现新的bug
3、单位时间内查出的bug数低于预定值
4、查出一定预定数量的bug


# 软件测试基础

软件测试16种类型
一：功能测试（10个方面）
菜单、工具栏、快捷键、下拉框、按钮、单选按钮、复选按钮、切换、链接、触发键
二：界面测试
登陆界面、总界面、输入界面（增、删、改、查）、处理界面、输出界面、报表界面、提示界面
三：容错测试
数据长度、数据类型、非法此操作
四：接口测试
接口测试也叫业务流程测试（包括功能模块之间、模块与模块之间、子系统之间）
内部接口：例如：导入、导出（通俗的讲是接口就是调用）
外部接口：
五：性能测试（TPS吞吐量、响应速度、cpu占用率、内存占用率）
平均吞吐量：单位时间内处理事务的个数
平均响应速度：做一个事务处理所用时间
例如：界面操作效率测试；报表输出及查询效率测试
六：负载测试（压力测试、强度测试、容量测试）
压力测试即就是大用户测试（针对B/S而言）
容量测试即就是大数据量测试
七：并发测试
指多个用户在同一时间对同一条数据的删除或者修改等处理
八：稳定性测试
例如：1小时触发600条信息，那么8个、10个等发信息的条数测试
九：恢复测试
突然断电（系统触发正常启动；数据包要在断电的地方继续进行处理）
十：配置测试
最低配置：
推荐配置：大多数用户所用的配置
十一：安装测试
安装过程；卸载过程
十二：文档测试
交给用户的文档。例如：系统帮助、用户使用手册、用户安装手册
十三：可用性测试（纯粹靠经验）
十四：初始化测试
是指系统刚刚安装完成后，在数据位空的情况下，如果被调用的模块为空，点击调用模块的时候，是否进行容错的测试。
十五：数据完整性测试
是指当主表的某一条件信息被删除后，和这一条相关的从表的信息都应该被删除。
如果某些数据的主键是由数据库本身而实现的，可以不用删除，如果有些主从表是由程序员写的代码而实现，则要进行数据完整性的测试。
16种测试类型归类
1、此软件能做什么？
针对数据进行”功能、接口、容错、界面、权限、初始化、数据完整性测试“
2、软件做的怎么样？
性能、负载、恢复、稳定性、并发、系统安全
3、软件在什么环境条件下做？
配置、安装、文档、可用性



软件测试的概念
通过一系列手段去证明软件是符合用户需求的，满足质量要求的。预期结果和实际结果的一个对比。
 
软件测试分类
按方法分：黑盒测试、白盒测试、灰盒测试
 
黑盒测试：把软件比作一个“黑匣子”，不考虑具体是内部是如何实现的，只考虑外部功能的运行，检查软件的输入和输出是否匹配。
 
白盒测试：检查软件的代码、函数和方法等内部结构。
 
灰盒测试：介于白盒和灰盒测试之间，既可以根据外部暴露出的功能进行检测，也可以参考内部的代码结构。
 
2.按方向分：功能测试、性能测试、安全测试
 
（1）功能测试：测试产品的功能，以确定是否满足设计需求。
 
（2）性能测试：分为客户端测试和服务器端测试（一般默认是服务器端测试）。
 
客户端性能测试：启动速度、消耗资源（CPU、内存、硬盘、流量、电量）
 
服务端性能测试（默认）：压力测试、负载测试、并发测试
 
o压力测试：获取系统正确运行的上限，检查软件在瞬间峰值的情况下是否能够正确运行。（通过多线程模拟）
 
o负载测试：在峰值的持续压力下运行软件，看软件的承载极限达到什么程度。
 
o并发测试：检查在并发条件下，会不会出现数据错乱的情况。（比如淘宝秒杀）
 
（3）安全测试：流量攻击、渗透、SQL注入、跨域攻击、爆破、劫持。
 
流量攻击：模拟大量用户访问服务器，不进行任何有效操作，无端消耗服务器资源。
 
渗透测试：发现软件系统中存在的漏洞，判断系统的安全性。
 
SQL注入：通过数据库的关键字进行异常操作，恶意执行不相干的SQL命令。
 
跨域攻击：诱导用户访问非法网站，利用会话信息模拟请求，盗取和篡改数据。（比如qq盗号）
 
暴力破解：写相应的脚本，用穷举法不断尝试破解对方的信息。
 
劫持：比如通过不安全的wifi连接，进行表单提交的操作，造成数据泄露。（还有网页广告弹窗等）
 
3.按阶段分：单元测试、集成测试、系统测试、验收测试
 
单元测试：最小模块的测试，可以是对代码、函数、方法进行白盒测试，一般由开发人员执行。
 
集成测试：主要是测试接口，所以也叫接口测试。（接口：模块与模块之间数据交换的通道。）
 
系统测试：对系统的功能、性能、安全、UI、稳定性、易用性、兼容性等进行测试。
 
验收测试：软件发布之前进行的测试，这是测试的最后一个阶段，也叫交付测试，评估产品是否可以发布。
 
4.按对象分：web测试、app测试、小程序测试、车联网测试、物联网测试
 
测试方法与测试对象无关，测试流程基本都是通用的。
 
5.按状态分：动态测试、静态测试
 
动态测试：运行软件，判断软件运行结果与预期结果的差异，检查软件的正确性。（黑盒测试）
 
静态测试：不运行软件，检查软件代码、方法、函数、文档的正确性。（白盒测试）
 
6.其他：回归测试，冒烟测试、α测试、β测试
 
回归测试：检查开发有没有把bug修改好，重新测试一遍，以保持正确性。
 
冒烟测试：测试前的测试，检查开发是否进行自测，软件是否具有可测试性。
 
α测试：产品内测。
 
β测试：产品公测。
 
软件基本结构
 
软件 = 程序+数据+文档
 
基本结构：
 
B/S（浏览器/服务器），C/S（客户端/服务器）
主要区别：是否需要单独安装/更新客户端
前端
用户端（前台）
app：andriod（android、kotlin），ios（swift，object-c）
web：html，css，JavaScript
小程序
管理员端（后台）
主要是web
后端
#服务器上运行，断网无法使用,一般是linux环境
数据库
运行环境：java，php，python，.net，go
服务器软件：tomcat，apache，nginx，IIS
（c++一般用于桌面程序）
 
软件测试的方法
找到合适的测试数据
 
边界值
（左边界、右边界）：<=6,先测<6,再测=6，所以要取边界值和边界值旁边的点，5和6。
 
等价类  
 
有效等价类：比如0.01-200，0.01，200，0.02，199.99，100.05（保险起见还选了个中间值）
无效等价类：0，200.01
 
用户场景法
 
成功的场景：符合要求的金额和红包寄语（默认、0，25，1，25，12），发送红包成功
失败的场景：金额错误、寄语不符合要求（输入的值空，26）（空不等于空格）
 
了解概念
因果图
判定图
路径覆盖法
 
软件测试的模型
 
指的是研发模型（不仅仅是测试模型）
 
瀑布流
需求分析→软件设计→软件实现（编码）→软件测试→交付验收→实施维护
有完整上下结构，必须完成上一个步骤，才能开始下一个步骤。犯错成本高，容错率低，效 率低，维护成本高。
 
V字型
 
测试和开发的工作一一对应。必须完成上一个步骤，才能开始下一个步骤，效率低。
 
W字型（用得最多）
 
 
每个阶段测试和开发都有事做。第一个V代表开发，第二个V代表测试。
 
分别有什么优势和劣质？
 
H型
螺旋形
敏捷性（流行趋势）
集中办公，需要高管理水平的人才
 
搭建测试环境
一般搭建在服务器上。
服务器操作系统的选择：
windows（收费，商业系统，不可选的图形化界面）
OSX（苹果，贵）
Linux（开源，免费，可不选图形化界面，节约成本）：通过安装Linux系统或租云服务器获取
 
测试流程
 
需求分析阶段
（需求文档，场景原型，交互图，口述）
学习软件的功能、业务、流程
提取软件的功能点（画思维导图）
编写需求分析说明书
 
测试设计阶段
 
编写测试文档
测试计划：时间，人员，成本，申请资源、经费
测试策略：规定测试内容的深度和广度，测试内容的先后顺序
深度：是否做单元、集成、系统、验收测试
广度：系统测试的范围（功能、性能、安全、兼容性、易用性、稳定性）
测试方案：具体的测试内容，测试手段
测试用例：具体的测试步骤（excel表格）
测试用例的要素
编号（唯一），用例名称，前置条件，优先级，重要级，测试数据，测试步骤，预期结果，实际结果。
 
测试是无穷无尽的
测试评审：同行评审，小组评审，部门评审，项目评审，第三方评审，邮件评审
 
测试执行阶段
执行测试用例、提交bug（bug管理系统）、回归测试、跟踪管理bug，测试环境的搭建
和配置，申请资源
 
测试总结阶段
1.工作总结
 
2.bug统计分析
如禅道的报表功能，测试人员的提交bug数，开发人员的造成/修复bug数，不同软件模块的bug数，不同等级的bug数，解决bug的时间，每个版本的bug情况，bug的状态
 
3.软件质量评估
达到软件交付的标准：一二级bug全部关闭，三级bug关闭了80%以上，四级随缘
 
 
测试文档的编写
 
墨刀（画产品原型） 凹脑图
 
需求分析阶段：
 
需求分析说明书
 
 
除了功能点，还要列出限制条件，比如字符串长度，数字范围等。比如发红包功能，还要列出成功、失败场景。
 
测试计划：时间、人员、资源的分配，流程的管理。
 
测试方案：对每一项测试内容应该用到的测试方法、测试工具、测试开始/结束的标准进行描述。
 
测试策略：规定测试的范围，哪些阶段需要测试，测试的粒度（要测试多详细），测试顺序（哪些功能先测试），风险分析（最大程度的减少不相干因素的干扰）
 
以上三个文档经常合并，写进测试计划中。（多看模版）
 
测试用例：
5w1h
pdca（核心：不断优化）
 
测试文档：通过测试方法提取功能点，根据场景发提取测试点，根据季等价类、边界值设计测试数据，编写文档。
（mooc网浪晋：如何学好测试用例） 萌芽群里有测试用例模版。
 
系统测试用例
 
接口测试用例
 
测试应用
 
app测试（B/S），web测试（C/S）
 
app测试除了常见的测试之外，还有app专项测试：安装/卸载/修复/更新，消息推送，弱网（2G/3G/4G/5G/WIFI）测试，场景交互（来电话了，正在听音乐，摄像头，录音，前后台切换），权限测试（权限关闭和打开是否会影响功能的使用，需要时是否还能还会弹出权限提醒），离线测试。
 

# 系统业务指标


1、交易响应时间
不同行业不同业务可接受的响应时间是不同的，一般情况，对于在线实时交易：
互联网企业：500毫秒以下，例如淘宝业务10毫秒左右。
金融企业：1秒以下为佳，部分复杂业务3秒以下。
保险企业：3秒以下为佳。
制造业：5秒以下为佳。


2、系统处理能力
一般情况下，用以下几个指标来度量：
HPS（Hits Per Second） ：每秒点击次数，单位是次/秒。
TPS（Transaction per Second）：系统每秒处理交易数，单位是笔/秒。
此指标是衡量系统处理能力非常重要的指标，越大越好，根据经验，一般情况下：
金融行业：1000TPS~9000TPS
保险行业：100TPS~1000TPS
制造行业：10TPS~50TPS
互联网电子商务：10000TPS~100000TPS,例如天猫5万TPS
互联网中型网站：100TPS~500TPS
互联网小型网站: 50TPS~100TPS


3、并发用户数
可以选取高峰时刻，在一定时间内使用系统的人数，这些人数认为属于在线用户数，并发用户数取10%就可以了，例如在半个小时内，使用系统的用户数为10000，那么取10%作为并发用户数基本就够了。


总结：
系统的性能由TPS决定，跟并发用户数没有多大关系。在同样的TPS下，可以由不同的用户数去压（通过加思考时间设置）。
系统的最大TPS是一定的（在一个范围内），但并发用户数不一定，可以调整。
建议性能测试的时候，不要设置过长的思考时间，以最坏的情况下对服务器施压。
一般情况下，大型系统（业务量大、机器多）做压力测试，5000个用户并发就够了，中小型系统做压力测试，1000个用户并发就足够了。


# 性能测试

性能测试相关

并发性能测试过程
是一个负载测试和压力测试的过程，逐渐增加并发负载，直到系统的瓶颈或不能接收到的性能点，通过性能指标、资源监控指标来确定系统并发性能的过程
 
性能测试类型

疲劳强度测试：采用稳定运行情况下能够支持的最大并发用户数，持续执行一段时间业务，保证达到系统疲劳强度需求的业务量，通过分析指标，确定系统最大工作量强度性能

负载测试：通过逐步加压，在满足预期指定的性能指标情况下，系统所能承受的最大负载量
压力测试：通过逐步加压，确定系统在什么情况下会崩溃， 以此获取系统的最大负载量，什么条件下系统的性能会变得不可接受
 
性能测试过程中的功能校验是否必须？
不进行功能校验的话，忽略了负载压力情况下功能不稳定的问题，没有正确的功能保证，性能测试就没有意义了
副作用：需要断言/校验测试结果，会消耗一部分性能，导致最终测试结果不一定是最准确的
 
业务方面的性能测试
1、利用企业压测工具测试**，并发请求数是否满足基本业务需求
2、是否具备异地容灾备份
3、是否具备可伸缩配置及扩展能力
4、关键部分是否采用双机热备份和磁盘镜像
5、是否满足系统的不断运行、在线故障修复和在线系统升级
 
负载类型
并发用户数属于并发执行负载
连续稳定运行属于疲劳强度负载
大量检索操作属于大数据量负载
 
系统瓶颈
1、服务器CPU性能不足
2、程序没有采用合适的并发/并行的策略
3、服务器网络带宽不足
4、数据库设计不足、优化不够




基本概念
测试概念
转变思维
在做功能测试、自动化测试的时候，我们基本都是依托界面进行测试，也称 GUI 测试，我们的目的就是为了跑通功能、程序，并成功找到 Bug
但在做性能测试的时候，我们大部分是 headless 模式（所谓的：无头，无界面模式），目的不再是单纯的为了找到 Bug，而是要分析性能指标等等（后续讲到）
 
性能测试的时间一般会比自动化、功能测试长，为啥？
因为性能测试的步骤跟自动化、功能测试的步骤不一样，比如说前期的准备（了解系统，环境搭建），后期的压力测试（7*24h）等等
在后面，我们通过讲述性能测试步骤来仔细了解
 
性能测试一定要工具，手工不行吗？
性能测试是模拟系统在被很多很多用户同时使用时，系统能不能正常使用和提供服务
重点：很多很多用户
功能测试：一个人点点点就知道功能通不通，有没有 Bug 了
性能测试：用手工的话，可以模拟几个、十几个用户，但是当需要模拟上千万个用户时，手工又怎么模拟数据量多的场景呢？
类比，吃饭场景：一个人可以吃好几碗，但是叫你吃几百碗是不可能的
结论：工具就可以模拟大数据量的场景，可以做到人做不到的事情
 
大数据量测试是性能测试吗？
大数据量测试
简单理解：一个接口返回的数据比较多（假设：不使用分页，把所有数据同时返回）
 
结论
返回大数据量的接口的响应时间会变长
这么大的数据量，我们需要考虑：网络传输数据、服务器查询这些数据、服务器处理这些数据等等分别需要多少时间
这已经跟响应时间挂钩，所以已经属于性能测试的范围，但不归纳于性能分析范围
 
大数据测试是性能测试吗？
大数据测试的功能属于功能测试哦
 
性能测试过程发现问题需要立即提交吗？
在性能测试过程中发现一些问题，假设定位到某一段代码有问题，可以截图提交 Bug 给开发，但这并不是我们性能测试的最终目的，最终目的是找出性能指标
 
有哪些性能指标？
比如说响应时间：10个人、100个人 、1000个人 、10000个人向服务器发起请求，服务器响应请求的平均响应时间是多少，这就是一个指标
又好比TPS：服务器在当前的配置下，不同用户数发起请求，服务器的 TPS 处理能力是多少，这也是一个指标
后续详细介绍
 
性能测试中发现的 Bug 
性能测试过程中发现的 Bug 属于一个衍生品，并不是最终得到的结果
但像功能测试，最终目的就是为了找出 Bug
 
关于这个问题的总结
做性能测试，当数据量变大后，会出现连接超时、连接拒绝、500、502等异常问题；在性能测试中，这些异常问题基本都会出现的，但不会去立即提 Bug
对于性能测试工程师，我们要做的是分析为什么在当前数据量下会出现连接超时、连接拒绝，响应时间超时、服务器异常等异常问题
这就需要我们去分析性能瓶颈，并不会单独去看某个异常问题出现在哪里，而是分析为什么会出现这个异常问题，分析的是服务器或者是代码，而不是让开发人员马上来修复这些异常问题
 
我们常说的压测是指压力测试吗？
并不是，而是指负载测试，一般都是为了找出系统的最大负载量
就好像你老板说：你去压测下，看看系统能支撑多少用户同时访问我们的系统
 
什么是性能测试？
狭义理解
通过工具，找出或获得系统在不同工况下的性能指标值
性能测试过程中，重点是找出性能指标，而不再是找出 Bug，
性能测试的产出绝对不只是 Bug
 
场景类比
跑步100米，用时多少？运动员的心跳、步伐频率是多少？
1.跑步100米：业务场景
2.用时多少：响应时间
3.运动员的心跳、步伐：性能指标值
性能指标值和响应时间是否满足当前业务场景的最低要求（合格线）
 
什么时候能找出性能指标值
假设当前有一个业务
电商系统，下单业务，目前还不知道系统支持多少人同时下单，那么我们需要找到服务器能正常支持多少人同时下单
 
性能测试初始阶段（第一次做）
先把基础的性能指标值找出来（第一次性能测试也叫做基准测试）
比如：100个人同时下单系统正常，但120个人同时下单就会出现部分请求的响应时间超长，连接异常
那么100-120范围内的某个值就是当前服务器能达到的性能指标值（基准值）
 
版本迭代，进行第二次做性能测试，重新跑一遍之前的性能脚本
又会得到一些性能指标值，对比上个版本的性能指标值，看是否有优化（性能变化）
假设这个时候120个人同时下单是正常的，150个人才有异常，那么接口已经有优化了
 
假设公司是从0开始做性能测试
第一阶段：做好性能测试，得到性能指标值
第二阶段：假设性能比之前差，哪些性能指标值不满足预期值，就需要分析是哪里有问题
 
广义理解
只要与服务器性能指标相关的测试都属于性能测试
比如：响应时间、并发用户数、服务器处理能力、吞吐量等性能指标
负载测试、压力测试、容量测试、可靠性测试都属于性能测试
通常嘴巴上说的做性能测试就是广义的性能测试，它包括了很多内容，并不只是针对某一个测试类型
 
“官方”解释
以下含义来源高老的解释，比较“官方”的术语
1.性能测试针对系统的性能指标，建立性能测试模型
2.制定性能测试方案
3.制定监控策略
4.在场景条件下执行性能场景
5.分析判断性能瓶颈并调优
6.最终得出性能结果来评估系统的性能指标是否满足既定值
其实也算是一个简洁描述的性测试流程了
 
注意
性能测试不像自动化测试那样很多东西大家都是公认的，性能测试没有一套标准的知识体系，只能说是相似的
基本每个人都有自己的一套知识体系，就好像高老也会说他给性能测试的定义很大可能会被轰炸一样
只要属于自己的知识体系建立起来了，那么就能助力你正确的完成性能测试
不用太过纠结于哪个人对性能测试概念的解释是最准确的
目前博主是正在学习性能测试的小白一枚，希望通过通俗简单的术语来学懂性能测试，打造属于自己的知识体系，欢迎大家进群与我沟通（870155189）
 
 什么是负载测试？
概念
逐步增加系统负载，测试系统性能变化，并最终确定系统所能承受的最大负载量
通俗理解：看看你几斤几两
 
如何增加负载
通过增加“用户数”，就是常说的并发数
 
场景类比
天平秤，称东西的时候，需要逐步加砝码，最终达到砝码和物品重量的平衡点，因为它不可能一下子就达到平衡点【好比不可能一下子找到系统能承受的最大负载量】
称东西：业务场景
加砝码：逐步加压
达到平衡点：找到最大负载量
 
实际场景
有一个业务，增加到40个人的时候，服务器还能正常使用，没有异常
当你增加到50个人的时候，服务器已经开始有异常了，那么就能确定40-50之间某个值就是系统所能承受的最大负载量【出现性能拐点，找到了服务器性能瓶颈的范围值】
最后减小加压梯度（比如：从40个人开始每次增加1个人、2个人），确认最大负载量【确认性能拐点】
 
服务器又有哪些可能会出现的异常呢
响应时间超长：正常服务器处理请求时间是 1s，但现在变成3s - 5s
服务报错：无法同时正常响应多个请求
服务器宕机：系统完全用不了
 
什么是压力测试？
概念
在较大的性能压力下，持续运行一个比较长的时间，看看系统服务是否正常及系统资源的利用率情况
通俗理解：鸭梨山大！
关键字：较大压力 + 较长时间
注意：不是满负荷压力哦
 
场景类比
问：大家什么时候会觉得工作压力大？
答：996、007；因为你不会觉得955压力山大吧
结论：所以在我们日常工作中，长时间工作强度高，才会觉得压力大；如果你一周就加班一天也说压力大...（那就别干这一行了）
 
压力测试用来干嘛的
测试系统的稳定性
 
类比
工作压力大，你还能坚持下去（那稳定性肯定好吧），那如果你很快就离职了（那稳定性肯定差，都宕机罢工了）
 
什么时候会做压力测试
生产环境下，系统隔三差五的出现不稳定的情况
这个时候，就需要通过压力测试去测试系统的稳定性情况
 
啥情况算不稳定？稳定性差？
隔三差五的出现下面的情况
服务异常：响应错误、响应时间超时等
服务器出现异常：宕机
 
怎么分析是服务异常还是服务器异常 
如果所有请求都是一片红，应用程序发送的所有请求都报红，就是服务器出现了异常
如果有些请求偶尔成功响应，偶尔又失败，则是服务异常，出现不稳定的情况
 
如何取压力值
在负载测试中，我们确认了系统所能承受的最大负载量
压力值 < 最大负载量，一般取80%左右
 
灵魂拷问
负载测试一般时间比较短，压力测试时间比较长，持续运行时间短就能正常使用，但持续运行时间长就可能崩掉了，这是什么原因呢？
 
场景类比
栗子一：电脑保持开机状态很长时间，会逐渐变卡，因为内存的东西会越来越多，得不到有效的回收， 就会越来越卡
栗子二：当你经常工作压力很大，且你的心理所能承受的压力逐渐达到最大值时，你就可能会选择离职
 
总结
压力测试长时间运行，可能会逐渐增加系统的内存占用空间，若得不到有效的内存回收，当达到内存最大值时，系统就会崩掉
 
压力测试持续运行时间要多久？
标准性能测试里面，一般是7*24小时，或者是它的倍数
但是实际工作中，并不会这么久，否则成本太高
所以会以小时为单位，比如：4个小时、8个小时...晚上下班之后做，第二天早上上班看结果
 
先负载测试还是压力测试？
先负载测试
负载测试可以找到服务器性能瓶颈的范围值，若生产环境中系统稳定性较差，再做压力测试
所以压力测试是可做可不做的
 
什么是可靠性测试？
概念
在给定的一定的业务压力下，持续运行一段时间，查看系统是否稳定
关键字：是否稳定，一定业务压力
注意：不是较大压力哦
 
业务场景栗子
电商秒杀场景，几十个商品几十万个人同时秒杀抢购
 
如何理解可靠性测试
1.编写性能脚本：假设一秒内有一万个人同时发起请求
2.有压力吗？有，一万个人同时发起请求
3.但是持续时间短，不像压力测试一样需要持续一段时间
4.目的是为了验证当这么多人同时发起请求时，成功秒杀的用户能否继续完成后续下单付款等操作【一定业务压力下，系统是否稳定运行】
 
什么是容量测试？
概念
在一定的软、硬件条件下，在数据库不同数据量级数据量的情况下，对系统中读/写比较多的业务进行测试，从而获得不同数据量级下的性能指标值
关键字：不同数据量级
 
数据库数据量对性能测试结果有没有影响？
肯定有
比如数据库已经有几百条数据和几百万条数据，查询的速度肯定不一样，所以肯定会影响性能测试结果
数据量级的差异，会影响TPS、响应时间、网络等
 
场景类比
从一袋米中找一个绿豆，和一碗米中找一个绿豆，找的时间肯定是千差万别的


性能测试步骤

性能测试的前提
必要性，是否有做性能测试的必要（关键项评估）
主管部门、监管部门审查
涉及生命财产安全
大型新系统
核心系统
架构调整
业务剧增
重大缺陷修复
 
可测性，可量化为性能指标值
一般有需求文档，根据老板或者产品提出的需求，我们需要将里面的需求内容量化为性能指标值，这是我们的性能指标预期结果
如果无法量化的话，我们就没有预期性能指标值，在性能测试中测出的性能指标值，没有可对比的值，那就不知道是否满足需求的需要
 
开展性能测试必备条件
独立网络
内网（zoom域）、外网独立分开，千万不要用跨内网外网
 
为什么要独立网络
在做性能测试会向服务器发送大量的请求，会有大量的网络传输，可能会出现网络堵塞
如果和功能测试人员使用的网络相同，将会导致功能测试时请求响应时间变长
 
建议使用直连的局域网
这不意味着要单独开辟一个条新的网线
注意：压力机和服务器之间不要通过wifi、vpn、堡垒机、跳板机来连接，他们很容易网络不稳定（如丢包），容易造成性能指标值不准确
建议：而使用局域网，有线网，压力机和服务器相连接的网络相对稳定，可以忽略网络延迟等网络因素影响性能测试结果
结论：如果连网络都得不到保障的话，那么测出来的性能指标值则不可信了，因为性能结果很可能会受网络因素的影响，从而导致和实际结果差异很大
 
如果使用公有云服务器
有内网、外网，测试时一般都是用公网，而上行会比较宽，可以基本忽略网络延迟
 
独立环境
功能测试不能和性能测试共用环境（测试环境）
在做负载测试的时候，会短时间内占用大量的系统资源，如果此时有功能测试正在进行中，很可能会导致功能的不稳定或异常
在做压力测试的时候，会长期占用系统的资源，导致一段时间内无法稳定进行功能测试
 
不能使用测试环境、生产环境
生产环境有真实用户的各种数据，数据量肯定非常庞大【用户数据庞大】
性能测试模拟大数据量测试，最终可能也会产生非常多的数据【产生数据】
这样一来，真实用户的数据+性能测试产生的数据混在一起，生产环境的数据量翻倍变多，会影响服务器对真实用户请求的响应时间【生产数据量变大，影响真实用户的响应时间】
性能测试产生的数据属于脏数据，不应该出现在生产环境中，所以性能测试不能在生产环境中进行，但硬件环境要尽可能一致【脏数据】
 
结论
所以，做性能测试需要有单独的一套环境，且硬件环境最好和生产环境一致
这样性能测试最终得到系统所能承受的最大负载量会更接近在生产环境中，系统所能承受的最大负载量
 
性能测试步骤
性能测试准备
需求分析，熟悉业务：确定需要重点关注的点，如TPS、响应时间（确定需要收集的性能测试指标值）
明确性能测试目标（预期性能指标值）和测试范围
了解软件功能、架构
制定测试方案、测试计划，做好工作量评估
制定测试模型（编辑测试用例）：比如负载测试，场景要如何设计
 
搭建性能测试环境
技术准备：选择性能测试工具；测试方案中涉及到的技术问题；测试数据的收集方案实现；如何监控系统资源
被测系统环境搭建（服务器、服务版本更新、数据库数据准备）
网络配置
创建初始数据，如：测试账号（预估并发量）
 
性能测试脚本开发
选取协议
制作脚本
调试脚本
验证脚本
 
性能测试执行
真正开始对服务器进行性能测试
试运行
场景执行
收集并整理测试数据
 
性能测试结果分析与调优
分析依据：结果图表
分析思路：服务器硬件瓶颈>网络瓶颈>服务器os瓶颈（参数配置、数据库、web服务器）>应用瓶颈（sql语句、数据库设计、业务逻辑、算法）
调优
修改脚本或场景
性能回归，和之前的测试数据进行对比，是否有优化
 
服务器硬件瓶颈
如果性能测试环境和生产环境的硬件相差甚远，那么硬件很大程度造成了性能瓶颈，也不用去分析后面可能会导致性能瓶颈的其他原因了
 
性能测试报告与结果跟踪
性能测试报告：整理调优前后的测试数据
性能测试问题跟踪
构建持久化的性能监听平台，监听线上服务器的系统资源



常用的性能指标

两种性能指标
业务指标
技术指标
通常我们会从两个层面定义性能场景的需求指标，它们有映射关系，技术指标不能脱离业务指标

 
并发
狭义
指同一个时间点执行相同的操作（如：秒杀）
 
广义
同一时间点，向服务器发起的请求（可能是不同的请求）
只要向服务器发起请求，那么服务器在这一时间点内都会收到请求（不管是不是同一个请求）
 
场景类比
高速公路上，同时有多少辆车经过同一个关卡，但不一定是同一个牌子的汽车
 
并发用户数（重点）
同一时间点，发出请求的用户数，一个用户可以发出多个请求
场景不一定是同一个
和 CPU、响应时间有关系
 
和并发的关系
假设有 10 个用户数，每个用户同一时间点内发起 2 个请求，那么服务器收到的请求并发数就是 20
 
性能测试小场景一
不同身份的用户，访问不同的页面或发起不同的请求（广义的并发）
观察 CPU 使用率和响应时间
 
性能测试小场景二
所有用户，同一个时间点发送同一个请求（狭义的并发）
观察 CPU 使用率和响应时间
 
系统用户数
系统累计注册用户数，不一定在线
注册之后也可以一直不在线
因为用户信息是存在数据库的，而数据库数据就是存在磁盘中，所以系统用户数和磁盘空间有关系
 
性能测试小场景
写一个脚本添加很多条用户信息插入到数据库
目的：测试系统容量，方便了解系统的最大容量
实际项目中，当系统容量接近最大容量时，系统需要进行容量扩容（加磁盘空间），否则就会爆掉
 
在线用户数
在线用户可能是正常发起请求，也可能只是挂机啥操作都没有，不一定同时做某一件事情
在线用户可能是游客（未注册的用户），也可能是系统用户（已注册的用户）
在线用户数≠并发用户数
和内存有关系
 
性能测试小场景
使用 Jmeter 让不同的用户不断上线，且不下线和发起其他请求，看看内存使用情况
实际场景：12306 以前很多用户在线，响应时间会拉的很长
 
线程数
在 jmeter 中，线程数和并发用户数等价【和CPU、响应时间有关系】
 
事务
客户端向服务器发送请求，然后服务器做出响应的过程
登录、注册、下单等功能都属于一个事务
一个事务可能会发起多个请求
 
jmeter 相关
jmerter 中，默认一个接口请求，就是一个事务；但也支持多个接口整合成一个事务
 
注意点
若一个业务或事务有多个接口，那么多个单接口的性能指标值相加 ≠ 业务或事务的性能指标值
 
再来看看有哪些常见的性能指标值

 
响应时间（Respose Time）
响应时间对于性能测试来说
从发起请求到收到请求响应的时间
包含了：Request Time 和 Response Time
等价于：发起请求网络传输时间 + 服务器处理时间 + 数据库系统处理时间 + 返回响应网络传输时间
 
 
对用户所感知的响应时间包括
用户客户端渲染时间（多了这个）
请求/响应数据网络传输时间
应用服务器处理时间
数据库系统处理时间
 
重点
在做性能测试时，要尽可能的降低网络传输时间，这样最终得出的 RT 会无限接近服务器处理时间，所以我们要把网络环境搞好
 
事务请求响应时间
完成单个事务所用的时间，可能包含了多个请求
 
假如用户说应用很慢，要怎么分析？（仅供参考）
单个用户慢？还是多个用户慢？手上只有我们自己的应用慢？还是所有应用都这么慢？
网络问题的话，带宽是用哪家营业商？不同营业商是不是都卡？还是只有用户所在的营业商卡？
.....等等等
 
响应时间多少合理？
标准是：2、5、8
2秒：很好
5秒：可以接受
8秒：不能接受
 
TPS（Transaction Per Second，最主要的指标）
服务器每秒处理事务数，衡量服务器处理能力的最主要指标
 
知道 T 是如何定义的
在不同的行业、业务中，TPS 定义的颗粒度可能是不同的
所以不管什么情况下，需要做性能测试的业务的相关方都要知道你的 T 是如何定义的 
 
定义 TPS 的粒度
一般会根据场景的目的来定义 TPS 的粒度
接口层性能测试：T 可以定义为接口级
业务级性能测试：T 可以定义为每个业务步骤和完整的业务流
 
栗子

如果要单独测试接口 1、2、3，那么 T 就是接口级
如果从用户角度下订单，那 1、2、3 都在一个 T 中，就是业务级
结合实际业务设计，库存服务一定是同步，而积分服务可以是异步，所以这个下单业务，可以只看作由 1、2 这两个接口组成，但是 3 接口还是要监控分析的
 
所以，性能中 TPS 中 T 的定义取决于场景的目标和 T 的作用
 
拿上图做个例子
接口级脚本
——事务 start（接口 1）
接口 1 脚本
——事务 end（接口 1）
——事务 start（接口 2）
接口 2 脚本
——事务 end（接口 2）
——事务 start（接口 3）
接口 3 脚本
——事务 end（接口 3）
 
业务级接口层脚本（就是用接口拼接出一个完整的业务流）
——事务 start（业务 A）
接口 1 脚本 - 接口 2（同步调用）
接口 1 脚本 - 接口 3（异步调用）
——事务 end（业务 A）
 
用户级脚本
——事务 start（业务 A）
点击 0 - 接口 1 脚本 - 接口 2（同步调用）
点击 0 - 接口 1 脚本 - 接口 3（异步调用）
——事务 end（业务 A）
 
总结
一般情况下，我们会按从上到下的顺序一一来测试，这样路径清晰地执行，容易定位问题
 
QPS（Queries per Second）
每秒查询率，在数据库中每秒执行 SQL 数量
一个请求可能会执行多条 SQL
某些企业可能会用QPS代替TPS
也是衡量服务端处理能力的一个指标，但不建议使用
 
RPS（Request per Second）
简单理解
每秒请求数，用户从客户端发起的请求数
 
深入挖掘
对于请求数来说，也要看是哪个层面的请求，把上面的图做一点点变化来描述请求数

如果一个用户点击了一次，发出来 3 个 HTTP Request，调用了 2 次订单服务，调用了 2 次库存服务，调用了 1 次积分服务
问：Request 数量如何计算
答：3+2+2+1 = 8？不， 应该是 3，因为发出了 3 个 Request，而调用服务会有单独的描述，以便做性能统计
 
 
HPS（Hit per Second）
点击率，每秒点击数
可直接理解为用户在界面上的点击次数
一般在性能测试中，都用来描述 HTTP Request，那它代表每秒发送 HTTP 请求的数量，和 RPS 概念完全一样
HPS 越大对 Server 的压力越大
 
CPS/CPM（Calls Per Second/ Calls Per Minutes）
每秒/每分钟调用次数
通常用来描述 Service 层的单位时间内被其他服务调用的次数
 
栗子
上图的订单服务、库存服务、积分服务，各调用了2、2、1次，还是比较好理解的
 
TPS、QPS、RPS、HPS、CPS 的总结
有很多维度可以衡量一个系统的性能能力，但是如果把五个指标同时都拿来描述系统性能能力的话，未必太混乱了
 
为此我们可以这样做
用 TPS 来统一形容系统的性能能力，其他的都在各层面加上限制条件来描述，比如说：接口调用 1000 Calls/s
在团队中要定义清楚术语的使用场景，还有含义
 
吞吐量（Throughput）
单位时间内，网络处理的请求数量（事务/s）
网络没有瓶颈时，吞吐量≈TPS
 
吞吐率
单位时间内，在网络传输的数据量的平均速率（kB/s）
 
资源利用率
服务器资源的使用程度，比如服务器（应用、服务器）的CPU利用率，内存利用率，磁盘利用率，网络带宽利用率
一般不超过80%
 
Think Time 思考时间
从业务角度看
它指的是用户进行操作时，每个请求之间的时间间隔
比如：加入购物车后，多久之后会点击下单？浏览一个商品多久会加入购物车
 
从性能测试角度看
为了模拟用户两次操作之间的时间间隔，才有 Think Time，更加真实的模拟用户的真实操作
它和用户行为有关系，所以应该分析的是用户行为而非用户数
 
结尾
本篇博文，部分参考了高老师的《性能测试实战30讲》，因为指标那一块讲的特别好哦~





性能测试概念
性能测试针对系统的性能指标，建立性能测试模型，制定性能测试方案，制定监控策略，在场景条件之下执行性能场景，分析判断性能瓶颈并调优，最终得出性能结果来评估系统的性能指标是否满足既定值。

1.性能测试指标
时间指标
容量指标
资源率指标
2.性能测试模型
真实场景的抽象，可以告诉性能测试人员，业务模型是什么样子。 选择适合自己系统业务逻辑的方式，用最低的成本、最快的时间来做事情。
3.性能测试方案
方案规定的内容中有几个关键点，分别是测试环境、测试数据、测试模型、性能指标、压力策略、准入准出和进度风险。
4.性能测试监控
要有分层、分段的能力，要有全局监控、定向监控的能力。
5.性能测试预定条件
包括软硬件环境、测试数据、测试执行策略、压力补偿等内容。
6.性能测试场景
①.在既定的环境（包括动态扩展等策略）、既定的数据（包括场景执行中的数据变化）、既定的执行策略、既定的监控之下，执行性能脚本，同时观察系统各层级的性能状态参数变化，并实时判断分析场景是否符合预期。
②.性能场景分类 
基准性能场景
容量性能场景
稳定性性能场景
异常性能场景 

7.分析调优
①.对性能项目分类 
新系统性能测试类：这样的项目一般都会要求测试出系统的最大容量。
旧系统新版本性能测试类：这样的项目一般都是和旧版本对比，只要性能不下降就可以根据历史数据推算容量，对调优要求一般都不大。
新系统性能测试优化类：这类的系统不仅要测试出最大容量，还要求调优到最好。
②.性能团队的职责 
性能验证：针对给定的指标，只做性能验证。
性能测试：针对给定的系统，做全面的性能测试，可以得到系统最大容量，但不涉及到调优。
性能测试 + 分析调优：针对给定的系统，做全面的性能测试，同时将系统调优到最优状态。
8.性能测试结果报告
调优前后的 TPS、响应时间以及资源对比图。



性能指标


通常都从两个层面定义性能场景的需求指标：
业务指标
技术指标
技术指标不能脱离业务指标，下图说明了业务指标与性能指标之间的关系and所有的技术指标都是在有业务场景的前提下制定的：

 
性能测试行业常用的性能指标表示法：

 
用户数、线程数与TPS之间的关系：

 

性能测试工具


1.性能测试工具列表

2.工具对比

3.总结
压测工具也好，压测平台也好，都没有一个工具可以直接告诉你瓶颈在哪里，能告诉你的只是数据是什么。分析只有靠自己


并发用户数计算


1.并发 
一般使用TPS（ 每秒事务处理量(TransactionPerSecond)）来承载并发的概念
通常所说的并发都是指服务端的并发，而不是指压力机上的并发线程数，因为服务端的并发才是服务器的处理能力
    例如：下图并发数是16TPS，就是1秒内整个系统处理了16个事务 
    
  
  
2.在线用户数、并发数计算 
为了能 hold 住更多的用户，通常都会把一些数据放到 Redis 这样的缓存服务器中。因此对于一个设计逻辑清晰的系统来说，可以直接拿缓存的内存来计算，如一个用户进入系统需要10k内存来维护一个用户的信息，那么10G内存就能hold住1048576个用户数据，这就是最大的在线用户数，一般会将超时放在一起考虑。
对应关系
计算逻辑：  
          ①.如果有 10000 个在线用户数，同时并发度是 1%，那显然并发用户数就是 100
          ②.如果每个线程的 20TPS，显然只需要 5 个线程就够了（请注意，这里说的线程指的是压力机的线程数）
          ③.这时对 Server 来说，它处理的就是 100TPS，平均响应时间是 50ms。50ms 就是根据 1000ms/20TPS 得来的（这里                        说的平均响应时间会在一个区间内浮动，但只要 TPS 不变，这个平均响应时间就不会变）
          ④.如果我们有两个 Server 线程来处理，那么一个线程就是 50TPS
3.TPS计算公式 




性能分析思路

一.性能测试分析的能力阶梯视图

二.性能分析思路大纲
瓶颈的精准判断
线程递增的策略
性能衰减的过程
响应时间的拆分
构建分析决策树
场景的比对
1.瓶颈的精准判断
响应时间是用来判断业务有多快的，而 TPS 才是用来判断容量有多大的。
TPS曲线
oTPS衰减图：

随着用户数的增加，响应时间也在缓慢增加。
TPS 前期一直都有增加，但是增加的幅度在变缓，直到变平。
oTPS曲线可以告诉我们：
有没有瓶颈：其实准确说所有的系统都有性能瓶颈，只看我们在哪个量级在做性能测试了。
瓶颈和压力有没有关系：TPS 随着压力的变化而变化，那就是有关系。不管压力增不增加，TPS 都会出现曲线趋势问题，那就是无关。
响应时间
o响应时间图

o对应线程图

o对应TPS图

通过上图三个图我们可以看出，到第40个线程时，TPS基本上达到上限，为2500左右，响应时间随着线程数的增加而增加了，系统的瓶颈也出现了。
2.线程递增的策略
对一个系统来说，如果仅在改变压力策略（其他的条件比如环境、数据、软硬件配置等都不变）的情况下，系统的最大 TPS 上限是固定的。
对于场景中线程（有些工具中叫虚拟用户）递增的策略，我们要做到以下几点： 
o场景中的线程递增一定是连续的，并且在递增的过程中也是有梯度的。
o场景中的线程递增一定要和 TPS 的递增有比例关系，而不是突然达到最上限。
o对于秒杀类的场景，我们前期一定是做好了系统预热的工作的，在预热之后，线程突增产生的压力，也是在可处理范围的。这时，我们可以设计线程突增的场景来看系统瞬间的处理能力。如果不能模拟出秒杀的陡增，就是不合理的场景。
3.性能衰减的过程
压力产生结果图

通过计算可以得到统计图

o通过对比知道， 当每线程每秒的请求数降到 55 左右的时候，TPS 就达到上限了，大概在 5000 左右，再接着往上增加线程已经没有用了，响应时间开始往上增加了。这就是性能衰减的过程（在上图中，在红线前面，性能在上升的过程中有几次抖动，这个抖动到后面变大了，也变频繁了，如果这是必然出现的抖动，那也是配置问题。）。
o通过上述栗子可以得出： 只要每线程每秒的 TPS 开始变少，就意味着性能瓶颈已经出现了。但是瓶颈出现之后，并不是说服务器的处理能力（这里我们用 TPS 来描述）会下降，应该说 TPS 仍然会上升，在性能不断衰减的过程中，TPS 就会达到上限。
4.响应时间拆分
响应时间通常是一个分析的起点， 在压力工具上看到的响应时间，都是经过了后端的每一个系统的。那么，当响应时间变长，我们就要知道，它在哪个阶段时间变长了。
比如架构如图所示，拆分时间应该是比较清楚的：

5.构建分析决策树
分析决策树， 是对架构的梳理，是对系统的梳理，是对问题的梳理，是对查找证据链过程的梳理，是对分析思路的梳理。它起的是纵观全局，高屋建瓴的指导作用。
分析决策图

o从压力工具中，只需要知道 TPS、响应时间和错误率三条曲线，就可以明确判断瓶颈是否存在。再通过分段分层策略，结合监控平台、日志平台，或者其他的实时分析平台，知道架构中的哪个环节有问题，然后再根据更细化的架构图一一拆解下去。
数据库分析决策树，对 RDBMS 中的 MySQL，可以画一个如下的决策树

操作系统分析决策树

6.场景的对比
当你觉得系统中哪个环节不行的时候， 又没能力分析它，你可以直接做该环节的增加。


性能脚本


HTTP 是通过 Socket 来使用 TCP 的，Socket 做为套接层 API，它本身不是协议，只规定了 API。
通常在JMeter 中写 TCP 脚本，就是直接调用 Socket 层的 API。TCP 脚本和 HTTP 脚本最大的区别就是，TCP脚本中发送和接收的内容完全取决于 Socket server 是怎么处理的，并没有通用的规则。

一.编写Jmeter脚本
创建线程组

oNumber of Threads(users)：我们都知道这是 JMeter 中的线程数，也可以称之为用户数
oRamp-up Period(in seconds)：递增时间，以秒为单位。指的就是上面配置的线程数将在多长时间内会全部递增完。如果我们配置了 100 线程，这里配置为 10 秒，那么就是 100/(10s*1000ms)=1 线程 /100ms；需要注意的是，在 10 线程启动的这个阶段中，对服务器的压力是一样的。如图：

oLoop Count ：这个值指的是一个线程中脚本迭代的次数
oDelay Thread creation until needed：这里有一个默认的知识点，那就是 JMeter 所有的线程是一开始就创建完成的，只是递增的时候会按照上面的规则递增。如果选择了这个选项，则不会在一开始创建所有线程，只有在需要时才会创建。 如果不选择，在启动场景时，JMeter 会用更多的 CPU 来创建线程，它会影响前面的一些请求的响应时间。 如果选择了的话，就会在使用时再创建，CPU 消耗会平均一些，但是这时会有另一个隐患，就是会稍微影响正在跑的线程。这个选项，选择与否，取决于压力机在执行过程中，它能产生多大的影响。如果你的线程数很多，一旦启动，压力机的 CPU 都被消耗在创建线程上了，那就可以考虑选择它，否则，可以不选择。
oScheduler Configuration：举例来说，如果设置了 Loop Count 为 100，而响应时间是 0.1 秒，那么 Loop Count * iteration duration(这个就是响应时间) = 100 * 0.1 = 10秒。 即便设置了 Scheduler 的 Duration 为 100 秒，线程仍然会以 10 秒为结束点。 如果没有设置 Scheduler 的 Duration，那么你会看到，在 JMeter 运行到 10 秒时，控制台中会出现如下信息：
        INFO o.a.j.t.JMeterThread: Thread finished: Thread Group 1-10
1
创建HTTP Sampler

可以通过Method选择方法类型
手工编写 HTTP 脚本时，要注意以下几点： 
o要知道请求的类型，我们选择的类型和后端接口的实现类型要是一致的
o业务的成功要有明确的业务判断
o判断问题时，请求的逻辑路径要清晰
编写TCP脚本
o创建TCP Sampler

o输入配置和要发送的消息

相应断言
o定义： 断言指的就是服务器端有一个业务成功的标识，会传递给客户端，客户端判断是否正常接收到了这个标识的过程。

长短链接
o长短连接的选择取决于业务的需要，如果必须用短链接，那可能就需要更多的 CPU 来支撑；要是长连接，就需要更多的内存来支撑（用以保存 TCP 连接）


关联和断言

一.关联
哪些数据需要关联
o数据是由服务器端生成的
o数据在每一次请求时都是动态变化的
o数据在后续的请求中需要再发送出去

举个栗子， 常见的 Session ID 就是一个典型的需要关联的数据。它需要在交互过程中标识一个客户端身份，这个身份要在后续的交互中一直存在，否则服务端就不认识这个客户端了。Spring Boot 中有一个 spring-boot-starter-security，默认会提供一个基于 HTTP Basic 认证的安全防护策略。它在登录时会产生一个 CSRF（Cross-Site Request Forgery）值，这个值典型地处于动态变化中。
o可以看到登录信息返回csrf,没有使用这个值的接口将会没有权限访问。

o首先添加 Cookies Manage。JMeter 在处理 CSRF 时，需要添加一个 Cookies manager。如下：

o这里的 Cookie Policy 一定要选择 compatibility，以兼容不同的 cookie 策略。
o取动态值，在返回 CSRF 值的地方加一个正则表达式提取器来做关联。

o这里的，就是要取出这个动态的变化值，保存到变量 csrfNumber 中去。
o然后， 将发送时的 CSRF 值替换成变量，就可以正常访问其它接口了。

jmeter有多种提取器，使用什么样的提取器取决于业务的需要。
二.断言
断言就是判断服务端的返回是不是正确的，判断逻辑如下：

o举个栗子，登录接口：

o执行结果：

o添加断言：

总结
关联和断言的前半部分是一样的，都是从服务器返回信息中取出数据。但不同的是，关联取来的数据每次都会不同；而断言取出来的数据基本上都是一样的，除非出了错。
对服务端生成的，并且每次生成都不一样的动态变化的数据，那么将其取回来之后，在后续的请求中使用，这种逻辑就是关联。
对服务端返回的，可标识业务成功与否的数据，将其取回来之后，做判断。这种逻辑就是断言。

设置参数化数据


一.做参数化之前，应该考虑什么
在性能测试中，我们要关注的数据主要有：参数化数据、监控数据、基础铺地数据。
参数化测试数据的获取和考虑上，一般有以下疑问：
1.参数化数据应该用多少数据量？
2.参数化数据从哪里来？
3.参数多与少的选择对系统压力有什么影响？
4.参数化数据在数据库中的直方图是否均衡？
1.参数化数据应该用多少数据量
参数化数据要用到多少取决于场景，举例来说，对一个压力工具线程数为 100，TPS 有 1000 的系统，如果要运行 30 分钟，则应该取得的参数化数据是下面这样的。

我们需要保证测试时间足够长、满足测试的负载请求需求，根据「目标tps x 持续时间（秒级）」可以计算出参数化数大概的量级。
2.参数化数据从哪里来？
分为两种：
o死水数据，即out-of-box（事先创建测试数据），数据存在后台的数据库中；
o活水数据，即On-the-fly（实时创建），数据库不存在这些数据，构造参数化数据需要符合业务特点； 
通过 API 调用生成测试数据；
通过数据库操作生成测试数据；
要满足生产环境中数据的分布；要满足性能场景中数据量的要求
3.参数多与少的选择对系统压力有什么影响？
数据在系统中的流转：

满足测试的负载请求足够多和数据足够多样化，从而最大限度地减少或者掩盖缓存等其他因素的影响。参数取得过多，对系统的压力就会大；参数取得过少，不符合真实场景中的数据量，则无法测试出系统真实的压力。
4.参数化数据在数据库中的直方图是否均衡？
如果数据取自于数据图，我们通常要检查一下数据库中的数据直方图。 对于直接从生产上拿的数据来说，数据的分布更为精准。参数化数据需要符合真实业务数据分布情况，这样更符合业务真实场景。
二.如何设置参数化数据
例如用户登录， 以 JMeter 的 CSV Data Set Config 功能为例。配置如下：

o“Allow quoted data?”这里有两个选择，分别是 False 和 True。它的含义为是否允许带引号的数据， 比如说在参数化文件中有这样的数据：

如果有引号，这个选择必须是 True。如果设置为 False，那么我们在脚本中会看到如下的数据（由于设置为 False，JMeter 将（"）转换为了 %22 的 URL 编码）：
Java username=%22test00001%22password=%22test00001%22
oRecycle on EOF? ：这里有三个选择，False、True 和 Edit。False 是指在没有参数的时候不循环使用；True 是指在没有参数的时候循环使用。Edit 是指在没有参数的时候会根据定义的内容来调用函数或变量。
oStop thread on EOF?：这里有三个选择，False、True 和 Edit。同上。
oSharing mode : 这里有四个选择，All threads、Current thread group、Current thread、Edit。 参数是在所有线程中生效，在当前线程组生效，还是在当前线程中生效。但这里的 Edit 和前两个参数中的 Edit 相比，有不同的含义。这里选择了 Edit 之后，会出现一个输入框，就是说这里并不是给引用函数和参数使用的，而是要自己明确如何执行 Sharing mode。举个栗子， 假设我们有 Thread Group 1-5 四个线程组，但是参数化文件只想在 Thread Group 1、3、5 中使用，不想在线程组 2、4 中使用，那么很显然前面的几个选项都达不到目的，这时我们就可以选择 Edit 选项，在这里输入SharedWithThreadGroup1and3and5。而在其他的线程组中配置其他参数化文件。也就是说同样的一个变量名，在线程组 1/3/5 中取了一组数据，在线程组 2/4 中取了另一组数据。
o以上三个参数的选项可以随意组合。于是就会得到如下表（ EOF 是文件结束符的意思。在下面的解释中，为了更符合性能测试中的术语，特意解释为参数不足时）。

这个组合显然是矛盾的，没有参数时不让循环，还不让停止线程。

这个组合中第二个选项显然是没意义的，既然参数允许重复使用了，又怎么会发生参数不足停止线程的情况呢？

这个组合因为第一个选项为“Edit”所以变得不确定了，如果在 Edit 的函数或变量返回为 True，则和第 2 种组合一样；如果返回为 False，则和第 1 种组合一样。

这是一个合理的组合

第二个选项没有意义

这个组合同样因为第一个选项为 Edit，所以变得不确定了，如果在 Edit 的函数或变量返回为 True，则和第 3 种组合一样；如果返回为 False，则和第 4 种组合一样。

这个组合因为是否停止线程的不确定性会出现两种可能，有可能是第 1 种组合，也有可能是第 4 种组合。

这个组合中是否停止线程的 Edit 配置没有意义，因为可循环使用参数，所以不会发生参数不足导致线程停止的情况。

这个组合 具有相当的不确定性，有可能变成第 1、2、4、5 种组合。
其他衍生的设置组合：

性能工作中参数化的逻辑总结：
o分析业务场景；
o罗列出需要参数化的数据及相对应的关系；
o将参数化数据从数据库中取出或设计对应的生成规则；
o合理地将参数化数据保存在不同的文件中；
o在压力工具中设置相应的参数组合关系，以便实现模拟真实场景。


场景设计/监控设计

一.场景设计
在进行场景设计前，需要先列出要测试的业务比例、业务目标TPS和响应时间指标
业务不同，响应时间不同，需要给出每个业务的响应时间指标，假设以上响应时间统一，不大于100ms
1.基准性能场景
例如业务1
oStatistics

o上图TPS 达到 573.24，平均响应时间是 109.83ms，发送字节很少，这里都没统计到，接收字节 966.22KB/sec，这个值也非常低，最小响应时间 43ms，最大响应时间 694ms
o线程图

o响应时间

oTPS

已上四个图可以得到以下信息：
o场景是递增的
o压力线程上升到 55（第四个阶梯）时，TPS 达到上限 680 左右，但是明显的，性能在第三个阶梯就已经接近上限了
o在压力线程达到 55 时，响应时间达到 85ms 左右，这个值并不高
根据各个单业务得出单业务的容量结果，将结果得出以下一个表格

o由于设置的响应时间小于100ms,通过测试结果可以看到业务1已经接近指标，有可能出现峰值最大TPS超过承受值得情况
2.容量性能场景
对上述业务不断加压，等到如下结果 
oStatistics

o线程数

o响应时间图

oTPS细分图

o可以看出， 业务 4 和业务 5 的响应时间，随着业务的增加而增加，这显然在容量上会影响整体的性能
3.稳定性性能场景
稳定性场景的时间长度取决于系统上线后的运维周期
稳定性场景就是为了知道会不会由于长时间处理业务而引发潜在瓶颈 （像内存泄露是个典型问题），无需按照28原则，可按照最大TPS来跑
4.异常性能场景
异常性能场景要看架构图

o第一部分：业务应用服务器。停下如下区域的一半应用服务器，查看 TPS、响应时间及其他服务器压力
o第二部分：基础架构服务器。停下一半的基础架构主机，查看 TPS、响应时间及另外主机压力的恢复情况
o第三部分：数据库服务器。停下 master 数据库，查看切换时间，slave 的压力及 TPS 的恢复情况
o第四部分：启动 master 数据库
o第五部分：启动被停的应用服务
o第六部分：启动被停基础架构主机中的某个服务的某个节点
通过上述步骤，分析对应TPS图
二.监控设计
监控设计步骤
o首先，你要分析系统的架构。在知道架构中使用的组件之后，再针对每个组件进行监控
o其次，监控要有层次，要有步骤。有些人喜欢一上来就把方法执行时间、SQL 执行时间给列出来，直接干到代码层，让人觉得触摸到了最顶级的技能。应该是先全局，后定向定量分析
o最后，通过分析全局、定向、分层的监控数据做分析，再根据分析的结果决定下一步要收集什么信息，然后找到完整的证据链
监控技术图谱

微服务架构图

o做性能前，需画出系统对应的架构图

o全局监控
比如OS的全局监控

MySQL的全局监控分类

o定向监控
比如OS定向监控，当CPU消耗得多，需要对CPU进行定向监控

o监控工具





测试案例


一、性能测试需求分析与定义
通过前文性能测试需求分析对性能测试的必要性评估之后，敏捷开发团队确定利用开源工具JMeter实施性能测试工作。根据被测对象的应用特性，首先需要获取具体的性能测试需求。
 
1.性能需求关注的常规量化指标项
一般而言，被测对象的性能需求，会在用户SRS（需求规格说明书）中给出，如：单位时间内的访问量需达到多少、业务响应时间不超过多少、业务成功率不低于多少、硬件资源耗用要在一个合理的范围中，性能指标以量化形式给出。
对于相对规范的产品，产品团队一般会给出相对明确量化的性能测试要求，如下表所示：
 
测试项	响应时间	业务成功率	并发数	CPU使用率	内存使用率
随机购买商品	≤5s	100%	100	≤80%	≤80%
 
可以看出，上表给出的性能指标比较明确。性能测试活动实施过程中，测试工程师只需收集随机购买商品的 [响应时间、访问成功率、并发数、CPU使用率、内存使用率] 等相关指标的监测数据，与表中的量化指标比对即可。满足相关指标，则测试通过；若未满足，则需要进行问题分析定位，最终进行调优与回归，直至达到性能测试需求。
 
2.分析确定业务测试点，提取性能指标的策略
在有明确性能需求时，测试活动相对来说较为容易开展，但实际工作中，经常会碰到没有明确的性能需求的测试要求。因此，测试工程师需要具备根据不同输入（业务用户视角、终端用户调研、项目团队视角、运营团队视角、公司未来发展视角）分析，获取性能需求的能力。
以本次项目为例，产品团队并未指明性能测试需求，那么测试工程师如何分析提取量化的性能指标呢？
从用户应用角度考虑，若被测对象常用的业务的性能存在瓶颈，则很可能引起客户的反感。以登录功能为例，输入用户名和密码，点击登录按钮到显示成功登录信息，若耗时1min，用户绝对无法忍受。用户不常用的功能，如年度报表汇总功能，一个季度甚至是一年才使用一次，等几分钟or更长时间也有可能被接受。
So，不同的应用频率，决定了用户的使用感受，也决定了测试的需求。
针对本次ECShop电商系统而言，商城用户经常使用的功能，且存在大量用户使用的业务有：用户注册、登录、随机浏览商品、购买业务等，而其他功能则相对用户较少。若电商系统已经正式运营，则可从系统运营日志中分析具体的数据。若尚未上线运营，则需要调研用户or根据自身经验进行分析获取。
根据[JPT_01]性能测试需求分析中的描述，分析哪些是用户常用or交易占比超过80%的业务；从运营及项目组角度分析，哪些业务相对重要，然后确定为业务测试点。
综合分析，本次项目实践以用户登录、随机浏览并购买商品为测试点。确定业务测试点后，即可进行详细的业务需求分析，从而明确性能测试指标。
 
二、性能指标分析与定义
通常情况下，性能测试关注被测对象的时间特性、资源利用特性、稳定性。
时间特性：被测对象实现业务交易过程中所需的处理时间。从用户角度来说，越短越好
资源利用特性：被测对象的系统资源占用情况。一般Web系统不关注客户端的资源占用情况，仅关注服务器端，①通常为 服务端 的CPU、内存、网络带宽、磁盘等。根据被测对象架构设计，②还可分为 Web服务器、中间件、数据库、负载均衡...
稳定性：关注被测对象在一定负载情况下，持续稳定提供服务的能力
不同的被测对象，不同的业务需求，可能有不同的指标需求，但大多数测试需求中都包含以下几种性能指标：
 
1.并发数
并发数：①广义而言，是单位时间内同时发送给服务器的业务请求数，不限定具体业务类型；②狭义而言，是单位时间内同时发送给服务器的相同的业务请求数，需限定具体的业务类型。（在性能测试过程中需要区分二者）
服务端视角
并发，即同时出发，从应用系统架构层面来看，并发数为单位时间内服务端接收到的请求数。
客户端视角
客户端的某个具体业务行为包括多个请求，并发数可被抽象理解为客户端单位时间内发送给服务器端的请求数。
用户行为视角
客户端的业务请求一般为用户操作行为，并发数也可理解为并发用户数，而这些用户是虚拟的，又可称为虚拟用户数。
 
2.响应时间
目前，大多数软件系统客户端与服务器交互的过程，如下：
 
 
 
 	过程	处理时间
①	用户通过客户端向服务端发出业务请求	t1
②	服务端接收到请求，处理该请求	t2
③	服务端根据处理模型返回数据给客户端	t3
④	客户端接收到响应数据，处理数据呈现给用户	t4
 
系统视角
在整个处理流程中，系统的响应时间：T_s = t1+t2+t3。该时间没有包括客户端对数据处理并呈现的时间t4。
用户视角
从用户角度看，用户通过客户端发出业务请求，到客户端展现相应的请求结果，这个过程的时间越短越好。此时用户视角的响应时间：T_u = t1+t2+t3+t4。
服务器视角
从服务器角度看，服务器接收到客户端发送的请求，并给出结果的响应，这个过程所消耗的时间，记录为响应时间，即服务器仅关注t2的处理时间。
因此，不同的视角，衡量的响应时间指标也各不相同。实际测试过程中，需明确以什么视角验证被测对象的性能。
大多数情况下，性能测试响应时间主要以客户端发出请求，直至接收到服务端的响应数据过程中所消耗的时间作为参考。
严格来讲：响应时间=呈现时间+网络传输时间+服务器端响应时间+应用延时时间
Tips：
不建议尝试在公网进行性能测试，原因如下：
①可能影响现网用户。实施性能测试过程中，可能产生大量压力与垃圾数据，从而破坏生产环境，导致缺陷的产生，影响实际的业务。
②压力模拟可能无法体现真实场景。实施性能测试时，利用压测工具模拟大并发数，会产生大量业务数据。因负载生成器与服务器所在的网络不同，or服务器特定的网络安全设置，导致压力数据无法达到被测服务器，整个网络环境不可控，从而导致测试失败。
有一种情况除外，模拟固定带宽网络访问的场景，可在局域网中使用限制带宽的手段进行测试。
总之，需要遵循一个原则：在测试过程中，任何资源都必须可控。
 
3.吞吐量
吞吐量：单位时间内系统处理用户请求的数量。吞吐量指标直接体现了软件系统的业务处理能力，尤其适用于系统架构选型时做对比测试。
衡量方式：
请求数 / 单位时间
点击数 / 单位时间
字节数 / 单位时间
其中，[字节数 / 单位时间] 的计算方式，与当前的网络带宽比较，可找出网络方面的问题。
吞吐量计算：例如1分钟内系统可以处理1000次转账交易，则吞吐量为1000/60=16.7 (次/秒)
 
4.系统资源耗用
系统资源耗用：客户端与服务端系统各项硬件资源的耗用情况，如CPU使用率、内存使用率、网络带宽占用率、磁盘I/0输入输出量等。
一个系统的高效运行，除了软件性能要求外，还需要对硬件资源进行监控。若用户需求、项目组or其他利益相关方均未提出性能指标要求，则可参考行业经验，CPU使用率≤80%、内存使用率≤80%、网络带宽占用≤50% ...
CPU使用率
1）当CPU使用率超过80%时，表明CPU应用繁忙，如果持续维持在90%甚至更高，很可能导致机器响应慢、死机等问题
2）当CPU使用率过低时，说明CPU比较空闲，可能存在资源浪费的问题
内存使用率
对于内存，同样存在类似以上的问题
PS：
80%只是作为一个经验参考值，最终的性能测试指标需要经过项目相关各方评审才能确定
通过上述业务数据分析，最终得到本次项目测试的性能需求指标，如下：
 
测试项	响应时间	业务成功率	业务量	并发数	CPU使用率	内存使用率
登录	≤5s	100%	50000次/2h	100	≤80%	≤80%
随机购买商品	≤5s	100%	50000次/2h	100	≤80%	≤80%
 
5.业务成功率
业务成功率：用户发起了多笔业务请求中，成功笔数所占的比率。业务成功率展示了在特定压力or负载情况下，服务器正确、稳定处理业务请求的能力。
例如，测试银行营业系统的并发处理性能，有100个网点，上午10:00-11:00的一个小时高峰期里，要求能支持50000笔开户业务，其中成功率不低于98%，也就是需要成功开户49000笔，其他的1000笔可能是超时，或者其他错误导致未能开户成功。
 
6.TPS
单位时间内服务器处理的事务数。该指标值越大越好。一般情况下，用户业务操作过程可能细分为若干个事务，单位时间处理的事务数越多，说明服务器的处理能力越强。
 
三、综合分析：测试需求&指标分析
根据上述各指标，结合被测对象本身的业务情况，进行测试需求及指标分析：
ECShop是一个面向广大网络用户的电子商务系统，大部分用户会在某个时间段对平台访问、网购。
确定用户访问的峰值时间段：若新系统没有上线，没有历史数据可以依据，可通过竞品分析，获取友商系统的运营数据作为参考。
如业务峰值时间段：15:00-17:00、21:00-23:00，业务峰值期持续2h。若要测试稳定性，则需根据实际业务情况模拟用户应用场景。
 
 
 
确定在业务峰值时间段完成的业务量：需要统计有多少人在峰值时间段使用ECShop电商系统。
根据产品团队的业务规划、产品设计给出一个参考值，比如系统初期设计规模在单天15w业务量，峰值交易5000笔，最高并发100用户（如秒杀业务）。
通过对预设业务目标的分析，可得出以下数据：
-峰值持续时间：2h
-单天访问业务量：15w
-峰值交易笔数：5000
-最高并发数：100
在满足以上需求的同时，还需要考虑业务的响应时间。被测对象的响应时间，作为一个很直观的用户体验数据，可很好的衡量被测对象是否让用户体验良好，当然还需要把“体验良好”转换为量化的指标。
Apdex联盟-响应时间经验值
响应时间在业内的一个经验值，采用Apdex联盟的建议值：3s、3-12s，12s以上。0-3s的业务处理响应时间是非常理想的，而3-12s则是普遍可容忍的时间，但超过12s的响应时间，用户一般不会接受，可能选择刷新，甚至放弃操作。
“258原则”-响应时间参考值
1）当用户能够在2s以内得到响应时，会感觉系统的响应很快
2）当用户在2-5s内得到响应时，会感觉系统的响应速度还可以
3）当用户在5-8s内得到响应时，会感觉系统的响应速度很慢，但还可以接受
4）当用户在超过8s后仍然无法得到响应时，会感觉系统糟透了，or认为系统已经失去响应，而选择离开这个Web站点，or发起第二次请求
响应时间还应该根据业务类型确定，而不能仅从用户的主观感觉考虑。本次项目测试采用常规的5s为目标，也就是说ECShop平台处理登录、商品随机浏览购买等业务的服务器响应时间均不超过5s。
单天15w业务量，表明在一天内的总业务量为15w，但未明确是哪些业务的数据量叠加，还是每项业务都是此要求（假定单项业务每天都有15w的业务量）。
从上图 [访问时间-访问用户量] 坐标图中可以看出，用户访问并非是均分在24h内。在没有历史数据可依据的情况下，可利用经济学中的“28原则”进行分析，即80%的业务量集中在20%的时间段内完成。而单天峰值时间段共有2个：15:00-17:00、21:00-23:00。
计算业务量的分解数据：
80%的业务量：15w*80% = 12w
20%的时间段：24h*20% = 4.8h
单天峰值时间：2+2 = 4h
全天峰值时间 / 20%时间：4h/4.8h = 83.3%
以15:00-17:00、21:00-23:00为考察时间段，则预期业务量为：
12w*(4h/4.8h) = 10w
以15:00-17:00为考察时间段，则预期业务量为：
12w*(2/4.8) = 5w
综上，需要测试ECShop电商平台在2h内支持5w用户登录、随机浏览商品进行购买的业务。
 

# 可靠性测试


什么是可靠性
产品在规定的条件和时间内完成特定的功能，产品维持的性能指标
 
可靠性测试目的
1、发现软件系统在需求、设计、编码、测试、实施等各方面的各种缺陷
2、为软件的使用和维护提供可靠性数据
3、确认软件是否达到可靠性的定量要求
 
影响可靠性因素
环境、软件规模、软件结构、软件的可靠性投入
 
可靠性评价进程使用的定量指标
1、失效概率：指定时间范围内，软件失效的概率
2、可靠度：指定时间范围，条件下，软件不失效的概率
3、平均失效时间（MTTF）：软件运行后，到下一次出现失效的平均时间
4、失效严重强度：对用户具有相同程度影响的失效集合
 
可靠性措施
故障恢复：整个系统是否存在单点故障，对于关键性应用系统，当任何一台设备失效时，按照预先定义的规则是否能够快速切换；是否采用磁盘镜像技术，实现主机系统到磁盘系统的高速连接
数据备份：对于关键的业务，是否具备热备份机制，对于所有业务，是否提供磁带备份和恢复机制，保证系统能根据备份策略恢复到指定时间的状态
容灾备份：是否建立异地容灾备份中心，当主中心发生灾难事件时，由备份中心接管所有业务，是否能确保数据同步，快速可靠地与主中心的应用切换
敏感数据加密保护：需要测试相应敏感数据是否采用加密算法来加密保护
数据库访问方式：测试是否为不同应用系统或业务设置不同的专门用户用于数据库访问，杜绝在代码中使用超级用户及默认密码对数据库访问
 
可靠性测试过程步骤


# 安全测试


常见安全攻击手段
1、冒充：一个实体假装成一个不同的实体，常和消息篡改和重演一起使用
2、重演：当消息为了产生非授权效果而被重复时，就出现重演了
3、消息篡改：数据所传送的内容被改变而未被发觉，并导致非授权后果
4、服务拒绝：通过向认证/授权服务发送大量虚假请求，占用系统带宽造成关键服务繁忙，使得授权服务不能正常执行，产生服务拒绝
 
安全性测试方法（安全防护策略）
1、功能验证
2、侦听技术
3、模拟攻击试验
4、漏洞扫描：对软件系统和网络系统进行安全监测，以找出有安全隐患的漏洞
5、安全日志：记录非法用户的相关操作和信息
6、入侵检测：从系统内部和各种网络资源中主动采集信息，从中分析可能得网络入侵或攻击
7、隔离防护：将系统中的安全部分和非安全部分进行隔离，防火墙主要用于内网和外网的逻辑隔离
 
WEB应用的安全性测试
可以从部署与基础结构、输入验证、身份验证、授权、配置管理、敏感数据、会话管理、加密、参数操作、异常管理、审核、日志记录多个方面进行
 
关于SSL的的WEB应用安全性测试用例
1、SQL测试用例，账号输入name'--
2、https://替换成http://
3、内容访问，访问有文件的链接
4、内部URL拷贝：将登录后的URL拷贝出来，重启浏览器粘贴URL
 
防火墙测试点
1、是否支持交换和路由两种工作模式
2、是否支持对HTTP、FTP、SMTP等服务类型的访问控制
3、是否考虑到防火墙的冗余设计
4、是否支持对日志的统计分析功能，同时，日志是否可以存储在本地和网络数据库上
5、防火墙受攻击后，是否有告警方式
 
入侵检测系统
1、能否在检测到入侵事件时，自动执行切断服务，记录入侵行为
2、是否支持收集攻击信息
3、是否提供监视方式
 
对用户权限控制的测试
1、对用户权限控制体系合理性
是否采用分离管理模式
是否具有唯一性、口令的强度、存储位置、加密强度
2、对用户权限分配合理性
权限分配的细致程度
特定权限用户访问系统功能的能力测试
 
网页篡改途径
1、通过操作系统、网路服务、数据库漏洞
2、通过猜测/破解管理员密码
3、通过WEB漏洞或设计缺陷
 
防篡改系统的基本功能
1、自动监测
2、自动备份与恢复
3、自动报警
 
如何防篡改
1、修复漏洞
2、封闭未使用端口
3、设计安全性高的代码
4、设置强密码
5、安装防火墙
6、设置访问权限



# 性能测试理论基础
 
服务器
软件和硬件的整体。
硬件（物理元件）：
cpu（最重要）：
判断cpu好不好的两个主要指标：
1.主频（速度）:越大越好
2.核心数：越多越好
cpu使用率:服务器硬件的繁忙程度
内存：越大越好,读写速度快
IO：硬盘，越快越好(ssd固态硬盘比hhd机械硬盘快很多)
带宽：下载速度一般是1/10带宽，越大越好
 
 
web容器（应用服务器）：
1.tomcat （java）
2.weblogic
3.apache
4.php
5.iis（微软）
作用：开发的代码必须通过应用服务器进行部署，供用户访问
 
网关服务器：
平均分发请求
常用的网关：nginx（可支持百万级并发）
代理：
反向代理：不用关心过程（一般情况都使用反向代理）
正向代理：过程透明
缓存：
数据库最终是存放在硬盘中的，硬盘的读取速度慢。
优化：使用redis把数据库中的数据缓存在内存中，读取不到再去数据库找。
内存：读取速度快，断电数据丢失（所以服务器数据存在硬盘中）
硬盘：读取速度慢，断电数据保存
 
性能测试
定义：通过各种工具模拟多用户并发访问服务器，来测试服务器的性能
基于这个性能的黑客攻击：洪水攻击
分类：
压力测试：超出峰值的情况下的系统表现（大并发）
负载测试：逐步增加压力来试探服务器的性能
强度测试：长时间在峰值情况下运行，看能持续多久
并发测试：同时发送用户请求，强调功能性测试
（订单/奖品超发，库存和实际卖出不匹配）
目的：
性能拐点：服务器在什么情况下性能跑得最快
最大容量：服务器在多少并发时能够hold住
验证问题：使用方法还原bug场景，解决bug
 
判断性能拐点和最大容量
 
（软件方面）：
通过性能指标判断：
1.响应时间：平均响应，90%line（有90%的请求在x秒内完成）
258原则：2秒内很快，2-5还行，5-8等一等可以加载出来，8秒以后，很烂。
2.tps
每秒事务数，服务器每秒返回的请求数
可以通过tps找性能拐点：随着并发用户数的增加，tps出现峰值
 
 
3.事务失败率
失败事务数/事务总数
一般来说是<5%
 
（硬件方面）：
1.cpu使用率：长时间不能100%，持续小于85%
2.内存使用率：不同操作系统，内存调动机制不同。
linux/mac os机制：先把内存占满，再分配
Windows：要用的时候再分配内存
*所以linux直接看cpu使用率，要看单个进程（比如看tomcat，要看java程序，linux命令top可以看进程的占用内存情况）
内存泄漏（通常是java出现的问题，即tomcat要考虑的问题）：
tomcat一直把内存占着，越来越大，没有释放内存资源--发生内存泄漏。
判断内存是否足够：看虚拟内存是否足够，看IO使用率是否非常大。
 
性能测试开展步骤
1.需求分析：
对业务模型（多场景）有深入了解，了解用户使用场景：单场景（单个测试用例）、多场景（集合多个测试用例）
2.设计场景：
先考虑单场景的情况，然后组合在一起，考虑多/混合场景的情况。
3.编写脚本：
jmeter
loadrunner
接口和网页：app项目直接用接口，web项目要考虑静态资源：
1.静态资源（网页、图片、视频）：
静态资源不占cpu，即不需要进行计算，静态资源一般和带宽有关。所以不考虑带宽的话，一般不考虑静态资源。
2.服务器接口
4.执行测试：
loadrunner
jmeter（在cmd里输入jmeter，会出现提示：不要使用GUI模式做负载测试）
jmeter -n -t [jmx file] -l [result file] -e -o [Path to web report folder]
 
5,监控指标：
软件用工具监控
硬件：windows：任务管理器里有自带的性能资源监视器
linux ：系统自带的top命令，nmod，zabbix（后两个有权限的话可以试试），jmeter监控linux，loadrunner监控linux。
 
6.生成测试报告，分析结果
常见分析方法（控制变量法）：
1.性能拐点
2.服务是否崩溃：事务失败率，http状态码出现大量500+
3.最大容量：cpu使用率上限，响应时间，失败率（缺一不可）
4.内存泄漏：看jvm/java内存泄漏--查看java进程的内存大小，对比每一次的数据。在性能测试结束后，观察内存是否被释放。
 

# 接口测试
 
#接口测试工具：postman，Jmeter
 
接口测试文档必要信息
 
1.接口名称，接口地址url，
2.接口类型：
post 修改数据库数据，像服务器发送数据
get 从数据库读取数据
put，patch，delete，copy，head，options，link，unlink，purge，lock，unlock，propfind，view
3.接口参数：form-data，ram（text，json，xml），x-www-form-urlencoded,none,binary
4.请求头：headers
5.返回的数据
6.状态码
7.缓存（解决无状态连接的问题）：
session：存在服务器中，更安全
cookies：存在本地
*session存在于服务器中的账号密码，cookie相当于银行卡，token相当于银行卡密码。
 
网络知识
 
网络协议
1.tcp 速度慢，数据安全可靠（http不加密，https加密）
可靠原因：三次握手
2.udp 速度快，发送的数据不可靠
3.socket 一般用于客户端
协议缺陷：无状态连接，每次请求都是独立的，记不住上次的请求，所以要引入缓存。
 
ip
公网ip：运行商提供
局域网ip：
windows查看ip：进入cmd--输入ipconfig--看ipv4
linux查看ip：进入cmd--输入ifconfig --看inet
本机ip：localhost或127.0.0.1
查看特定网站的ip：进入cmd--输ping -www.baidu.com查看百度的ip
 
端口号
22:访问Linux服务器的默认端口
3306:访问mysql的默认端口
8080:访问tomcat的默认端口
 
域名
ip的别称，好记，花钱买。
 
 
bug的定位
集成测试（接口测试）：后端bug
系统测试：
1.看有没有操作接口
2.没有即前端的bug
3.有的话看状态码：
200一般是前端的bug，不过也有可能是代码没问题，功能写错了
4*，一般是前端bug
500 后端服务器bug
 
抓包工具
1.fiddle 免费，可抓web和app
2.network 浏览器自带（F12），抓web，选择XHR是看接口数据。
3.Charles 收费，可抓web和app
 
抓HTTPS的包
安装证书。
fiddle--tools--option--https--钩上前两个选项--弹窗都点yes。（没出现弹窗点actions）
 
对app进行抓包
 
fiddler是通过代理的形式进行抓包的一个抓包工具，默认的代理端口为8888。
1.要抓取手机app的数据包，要对fiddler进行设置，打开fiddler后，选择"Tools"项，在点击"Options"，进入到设置界面。
2.在"Options"界面，选择"Connections"项，检查"Allow remote computers to connect"是否勾选。
3.在配置手机代理设置前，需要知道电脑的IP地址，可以通过cmd中输入"ipconfig"查看。
4.进入到手机的wlan配置界面，点开已经连上的wlan，进入到该wlan的设置界面。
5.在wlan设置界面找到"代理设置"项，点击进入到代理设置界面，填入电脑ip和端口
号。
6.运行手机上的APP，然后观察fiddler，就可以发现抓取到了运行该APP的响应数据。
7.进入到"Tools"—>Options——>https项，选择"...from remote clients only"，这样就只显示抓到的手机上的数据包。
 

# 性能优化--后端服务

1、代码
优化代码实现是第一位的，特别是一些不合理的复杂实现。如果结合需求能从代码实现的角度，使用更高效的算法或方案实现，进而解决问题，那是最简单有效的。

2、数据库
数据库的优化，总体上有3个方面：
1）SQL调优：除了掌握SQL基本的优化手段，使用慢日志定位到具体问题SQL，使用explain、profile等工具来逐步调优。
2）连接池调优：选择高效适用的连接池，结合当前使用连接池的原理、具体的连接池监控数据和当前的业务量作一个综合的判断，通过反复的几次调试得到最终的调优参数。
3）架构层面：包括读写分离、主从库负载均衡、水平和垂直分库分表等方面，一般需要的改动较大，需要从整体架构方面综合考虑。

3、缓存
分类
本地缓存（HashMap/ConcurrentHashMap、Ehcache、RocksDB、Guava Cache等）。
缓存服务（Redis/Tair/Memcache等）。
设计关键点
1、什么时候更新缓存？如何保障更新的可靠性和实时性？
更新缓存的策略，需要具体问题具体分析。基本的更新策略有两个：
1）接收变更的消息，准实时更新。
2）给每一个缓存数据设置5分钟的过期时间，过期后从DB加载再回设到DB。这个策略是对第一个策略的有力补充，解决了手动变更DB不发消息、接收消息更新程序临时出错等问题导致的第一个策略失效的问题。通过这种双保险机制，有效地保证了缓存数据的可靠性和实时性。
2、缓存是否会满，缓存满了怎么办？
对于一个缓存服务，理论上来说，随着缓存数据的日益增多，在容量有限的情况下，缓存肯定有一天会满的。如何应对？
1）给缓存服务，选择合适的缓存逐出算法，比如最常见的LRU。
2）针对当前设置的容量，设置适当的警戒值，比如10G的缓存，当缓存数据达到8G的时候，就开始发出报警，提前排查问题或者扩容。
3）给一些没有必要长期保存的key，尽量设置过期时间。
3、缓存是否允许丢失？丢失了怎么办？
根据业务场景判断，是否允许丢失。如果不允许，就需要带持久化功能的缓存服务来支持，比如Redis或者Tair。更细节的话，可以根据业务对丢失时间的容忍度，还可以选择更具体的持久化策略，比如Redis的RDB或者AOF。
缓存问题
1、缓存穿透
描述：缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。
解决方案：
1）接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截。
2）从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用），这样可以防止攻击用户反复用同一个id暴力攻击。
2、缓存击穿
描述：缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。
解决方案：
1）设置热点数据永远不过期。
2）加互斥锁，业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。类似下面的代码：

public String get(key) {
    String value = redis.get(key);
    if (value == null) { //代表缓存值过期
        //设置3min的超时，防止del操作失败的时候，下次缓存过期一直不能load db
        if (redis.setnx(key_mutex, 1, 3 * 60) == 1) {  //代表设置成功
            value = db.get(key);
            redis.set(key, value, expire_secs);
            redis.del(key_mutex);
        } else {  //这个时候代表同时候的其他线程已经load db并回设到缓存了，这时候重试获取缓存值即可
            sleep(50);
            get(key);  //重试
        }
    } else {
        return value;
    }
}


3、缓存雪崩
描述：缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，缓存击穿是并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。
解决方案：
1）缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
2）如果缓存系统是分布式部署，将热点数据均匀分布在不同的缓存节点中。
3）设置热点数据永远不过期。
4、缓存更新
Cache Aside模式：这是最常用最常用的pattern了。其具体逻辑如下：
失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
命中：应用程序从cache中取数据，取到后返回。
更新：先把数据存到数据库中，成功后，再让缓存失效。

4、异步
使用场景
针对某些客户端的请求，在服务端可能需要针对这些请求做一些附属额外的事情，这些事情其实用户并不关心或者不需要立即拿到这些事情的处理结果，这种情况就比较适合用异步的方式去处理。
作用
异步处理的好处：
1）缩短接口响应时间，使用户的请求快速返回，用户体验更好。
2）避免线程长时间处于运行状态，这样会引起服务线程池的可用线程长时间不够用，进而引起线程池任务队列长度增大，从而阻塞更多请求任务，使得更多请求得不到及时处理。
3）提升服务的处理性能。
实现方式
1、线程（线程池）
采用额外开辟一个线程或者使用线程池的做法，在IO线程（处理请求响应）之外的线程来处理相应的任务，在IO线程中让response先返回。
如果异步线程处理的任务设计的数据量非常大，那么可以引入阻塞队列BlockingQueue作进一步的优化。具体做法是让一批异步线程不断地往阻塞队列里添加要处理的数据，然后额外起一个或一批处理线程，循环批量从队列里拿预设大小的数据，来进行批处理，这样进一步提高了性能。
2、消息队列（MQ）
使用消息队列（MQ）中间件服务，MQ天生就是异步的。一些额外的任务，可能不需要这个系统来处理，但是需要其他系统来处理。这个时候可以先把它封装成一个消息，扔到消息队列里面，通过消息中间件的可靠性保证把消息投递到关心它的系统，然后让其他系统来做相应的处理。

5、NoSQL
和缓存的区别
这里介绍的NoSQL和缓存不一样，虽然可能会使用一样的数据存储方案（比如Redis或者Tair），但是使用的方式不一样，这一节介绍的是把它作为DB来用。如果当作DB来用，需要有效保证数据存储方案的可用性、可靠性。
使用场景
需要结合具体的业务场景，看这块业务涉及的数据是否适合用NoSQL来存储，对数据的操作方式是否适合用NoSQL的方式来操作，或者是否需要用到NoSQL的一些额外特性（比如原子加减等）。
如果业务数据不需要和其他数据作关联，不需要事务或者外键之类的支持，而且有可能写入会异常频繁，这个时候就比较适合用NoSQL（比如HBase）。监控类、日志类系统通常会采集大量的时序数据，这类时序指标数据往往都是“读少写多”的类型，可以使用Elasticsearch、OpenTSDB等。

6、多线程与分布式
使用场景
离线任务、异步任务、大数据任务、耗时较长任务的运行，适当地利用，可达到加速的效果。
注意：线上对响应时间要求较高的场合，尽量少用多线程，尤其是服务线程需要等待任务线程的场合（很多重大事故就是和这个息息相关），如果一定要用，可以对服务线程设置一个最大等待时间。
常见做法
如果单机的处理能力可以满足实际业务的需求，那么尽可能地使用单机多线程的处理方式，减少复杂性；反之，则需要使用多机多线程的方式。
对于单机多线程，可以引入线程池的机制，作用有二：
1）提高性能，节省线程创建和销毁的开销。
2）限流，给线程池一个固定的容量，达到这个容量值后再有任务进来，就进入队列进行排队，保障机器极限压力下的稳定处理能力在使用JDK自带的线程池时，一定要仔细理解构造方法的各个参数的含义，如core pool size、max pool size、keepAliveTime、worker queue等，在理解的基础上通过不断地测试调整这些参数值达到最优效果。
如果单机的处理能力不能满足需求，这个时候需要使用多机多线程的方式。这个时候就需要一些分布式系统的知识了，可以选用一些开源成熟的分布式任务调度系统如xxl-job。

7、JVM优化
个人主要的后端语言是JAVA，对JVM进行优化也能一定程度上的提升JAVA程序的性能。JVM通常能够在软件开发后期进行，如在开发完毕或者是软件开发的某一里程碑阶段，JVM的各项參数将会直接影响JAVA程序的性能。
性能指标
关注以下指标：内存使用情况、CPU使用率、CPU load、GC count、GC time、GC日志。
查看java进程GC状态：jstat-gcutil{pid}1000
查看JVM默认的配置：java-XX:+PrintFlagsFinal-version|grep-iE'HeapSize|PermSize|ThreadStackSize'
jps：用来输出JVM中运行的进程状态信息。
jstack：用来查看某个Java进程内的线程堆栈信息。
jmap：用来查看堆内存使用状况。使用jmap-heap pid查看进程堆内存使用情况，包括使用的GC算法、堆配置参数和各代中堆内存使用情况。
查看java进程CPU高原因：
1）获取java进程pid：ps–ef|grep java
3）线程id转换为16进制：printf"%x\n"‘NID’
4）Jstack查看线程堆栈：jstack PID|grep'NID'-C行数–color
推荐2个java工具：1）show-busy-java-threads 2）arthas
优化方向
比如，JVM的堆大小（Xms、Xmx），垃圾回收策略等。要进行JVM层面的调优，需要对JVM的执行原理有一定的了解，如内存的结构，GC的种类等，然后根据应用程序的特点设置合理的JVM參数，但是GC tuning is the last task to be done.

 




站的性能测试
性能测试是性能优化的前提，也是性能优化结果的检查和度量标准。
性能测试的常用指标：
响应时间
并发数目
吞吐量。常用的吞吐量指标：
①TPS(每秒事务数)、
②HPS(每秒Http请求数)、
③QPS(每秒查询数，)
性能计数器。常用的性能计数器有：System Load、对象和线程数、CPU使用、内存使用、磁盘和网络IO等指标。性能测试的几个参考点：
性能测试
负载测试：系统的某项或者多想性能指标达到安全临界值时的并发数
压力测试
稳定性测试。PS：稳定性测试主要是长时间给系统一定的压力，看系统是否正常运行。
网站的性能优化三维度
后台服务器常用的优化方式
缓存
集群
异步
代码优化
存储优化
缓存相关知识
后台性能优化的第一定律：优先考虑使用缓存优化性能。
缓存的本质
缓存的合理使用
缓存可用性
缓存的常见问题处理与优化
分布式缓存架构
缓存的本质
缓存的本质就是一个内存Hash表，数据以一对KeyValue键值对存储在内存Hash表中。主要用户存放读写比很高、很少变化的数据，网站数据通常遵循“二八定律”，即80%的访问落在20%的数据上，因此，将这20%的数据缓存起来，可以很好的改善系统性能。
合理的使用缓存
合理的使用缓存对提高系统性能有很多好处，但是不合理的使用缓存反而会成为系统的累赘甚至风险。滥用缓存的三种情况如下：
频繁修改的数据
数据的读写比至少应该是2:1以上，即写入一次缓存，在数据更新前至少读写两次，缓存才有意义。真正实践中这个比例可能会更高。
没有热点的访问
如果应用系统访问数据没有热点，不遵循二八定律，即大部分数据访问并没有集中在小部分数据中，那么缓存也没有意义，因为大部分数据还没有被再次访问就已经被挤出缓存了。
数据的不一致与脏读
写入缓存的数据最好能容忍一定时间的数据不一致，一般情况下最好对缓存的数据设置失效时间(固定值+一定范围的随机值)。如果不能容忍数据的不一致，必须在数据更新时，删除对应的缓存(思考：为什么不是更新缓存)可以参考这个文档，但是这种情况只针对读写比非常高的情况。
缓存的常见问题优化手段
缓存雪崩
缓存雪崩我们可以简单的理解为：由于原有缓存失效，新缓存未到期间(例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期)，所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃。
该类问题的解决方式主要有三种：
①加锁排队。大概原理是在去数据库取数据的时候加锁排队，该方法仅仅适用于并发量不高的情况。
②在原有失效时间基础上加一个合理的随机值(0-5分钟)。分布式场景下最常见的方式(单机也可以)。
③给缓存加标记，在缓存失效之后更新缓存数据。
缓存穿透
缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。
该类问题的主要解决方式。
①使用布隆过滤器做过滤。该方法仅仅用于查询一个不可能存在的数据。
②把不存在的数据也缓存起来。最佳实践：单独设置比较短的过期时间，比如说五分钟。
缓存预热
缓存中存放的是热点数据，热点数据又是缓存系统利用某种算法对不断访问的数据筛选淘汰出来的，在重建缓存数据的过程中，系统的性能和数据库负载都不太好，那么多好的方式就是在缓存系统启动的时候就把热点数据加载好，这个缓存预加载的手段叫做缓存预热。对于一些元数据如省市区列表，类目信息，就可以在启动的加载数据库中的全部数据。
分布式缓存架构
分布式缓存是指缓存部署在多个服务器组成的集群中，以集群方式提供缓存服务，其架构方式有两种：
①以JBosss Cache为代表的需要更新同步的分布式缓存(在所有服务器中保存相同的缓存数据)。
②以Memcache为代表的互不通信的分布式缓存(应用程序通过一致性Hash等路由算法选择缓存服务器远程访问远程数据，可以会容易的扩容，具有良好的可伸缩性)。
异步
使用异步操作，可以大幅度改善网站的性能，使用异步的两种场景，高并发、微服务；
①高并发，在不使用消息队列的情况下，用户的请求数据直接写入数据库，在高并发的情况下会对数据库造成一定的压力，同时也使得响应延迟加剧。使用消息队列具有很好的削峰作用，在电子商务网站促销活动中，使用消息队列是常见的技术手段。
②微服务之间调用，在微服务流行的当下，有时候我们调用其他系统的微服务接口，只是为了通知其他系统，我们不关心结果，这个时候我们可以使用单独的线程池异步调用其他系统的微服务，这样可以减少程序的响应时间。
任何可以晚点的事情都应该晚点再做。
集群
在网站高并发访问的场景洗下，使用负载均衡技术为一个应用构建一个由多台服务器组成的服务器集群，可以避免单一服务器因负载压力过大而响应缓慢。常用的负载均衡技术有以下几种：
①HTTP重定向负载均衡，不利于SEO，不推荐。
②DNS域名解析负载均衡，许多DNS服务器还支持基于地理位置的域名解析，会将域名解析成距离用户地理最近的一个服务器地址，这样可以加快访问速度。大公司常用的手段。
③反向代理负载均衡(应用层负载均衡)，常见产品：Nginx,反向代理服务器的性能可能会成为瓶颈。
④IP负载均衡，在内核进程完成数据分发，叫反向代理负载均衡有更好的处理性能，网卡和带宽会成为主要的瓶颈。
⑤数据链路层负载均衡(三角传输模式)，又名DR(直接路由模式)，也是大型网站昌运宫的负载均衡手段，在Linux平台上最好的链路层负载均衡产品是LVS。
代码优化
网站的业务逻辑实现代码主要部署在应用服务器上，合理的优化代码也可以很好的改善网站性能。几种常用的几种代码优化方式：
①合理使用多线程，服务器的启动的线程数参考值：[任务执行时间/(任务执行时间-IO等待时间)]CPU内核数。
②资源复用，要尽量减少那些开销很大的系统资源的创建和销毁，比如数据库连接，网络通信连接、线程、复杂对象，从编程角度，资源复用主要有两种方式，单例、对象池。
③数据结构，前面缓存部分就已经提到了Hash表的基本原理，Hash表的读写性能在很大程度上依赖于HashCode的随机性，即HashCode越散列，Hash表的冲突就越少，目前比较好的Hash散列算法是Time33算法，算法原型为：hash(i)=hash(i-1)33+str[i]。
④垃圾回收，比如说在JVM里，合理设置Young Generation和Old Generation的大小，尽量减少Full GC，如果设置合理的话，可以在整个运行期间做到从不进行Full GC。
存储优化
在网站应用中，海量是的数据读写对磁盘访问会造成一定的压力，虽然可以通过Cache解决一部分数据读压力，但是很多时候，磁仍然是系统最严重的瓶颈。
机械硬盘VS固态硬盘
这两个的区别我相信大家都知道了吧，机械硬盘是通过马达驱动磁头臂带动磁头到指定的磁盘位置访问数据，这个效率我就不用多说了吧，相反，固态硬盘的数据是存储在可以持久记忆的硅晶体上，因此可以像内存一样随机访问，而且功耗更小。
B+树VS.LSM树
B+树是一种专门针对磁盘存储而优化的N叉排序树，以树节点为单位存储在磁盘中，从根开始查找所需的节点编号和磁盘位置，将其加载到内存中，然后继续查找，知道找到所需数据，目前大部分关系型数据库多采用两级索引的B+树，树的层次最多为3层。
目前很多NoSQL产品采用LSM树作为主要的数据结构，LSM树可以看做是一个N阶合并树，数据的写操作都在内存中完成，并且都会创建一个新记录，这些数据在内存中仍然还是一颗排序树。在需要读的时候，总是从内存中的排序树开始搜索，如果没有找到，就从磁盘的排序树中查找。
在LSM树上进行一次数据更新不需要磁盘访问，在内存中即可完成，速度远快于B+树，当数据访问以写操作为主，而读操作则集中在最近写入的数据上时，使用LSM树可以极大程度的减少磁盘的访问次数，加快访问速度。






软件研发量化指标
 
1.质量指标
 
 
2.缺陷等级
 


# 后端性能测试

数字货币交易平台后端性能测试思路

一、概述
数字货币交易平台通常提供：币币交易、合约交易、法币交易。本篇博客提供前面两者的一种性能测试思路。
关于需求的优先级
对于交易系统来说，“数据一致性”和“性能”的优先级排序上，前者优先级更高，因此一切性能测试的最终结果除了确认性能符合预期，也应包含对数据一致性的校验（如：资金的账户、金额、状态），并实现场景执行前、中、后的资金对账校验。
关于压测的关注点
交易系统功能核心是订单的处理，订单的处理主要包括：定序、撮合、清算。
定序也就是把用户的买、卖单按照价格和时间的优先级进行排序。
撮合也就是把用户的买、卖单按照排序结果进行交易、并扣取相应手续费。
清算也就是根据用户的挂单、合约盈亏进行账户资金更新。
目前大部分数字货币交易所的只有清算是基于数据库事务的，定序和撮合的工作在内存实现了。
业界所谓的支持高并发
某些交易所所谓的能支撑十万级、甚至百万级并发，实质上并不是指其撮合性能，而是指测试人员针对下单接口的压测得出的压测数据，和系统的实际撮合性能是两码事。试想，你挂了买单、市场上有个能和你撮合的卖单，但是系统就偏偏不做撮合，纯粹接口响应快又有什么意义？
小结
所以，对于数字货币交易所的压测，“性能”是否能够真正满足用户可以分成两个角度来观测：
用户看到的：即接口和推送的延迟，例如行情推送是否存在延迟、下单接口的反馈、委托当中委托的执行状态刷新延迟
用户看不到，但能被用户感知的：简单来说就是后台对订单的处理效率，例如：用户设置了止盈委托，行情也到达了止盈条件，但是委托单的执行总是需要延后几秒才反馈在交易页面，这种延迟又并非来自于推送或网络的延迟，而是系统对委托单的处理效率过低导致的
二、性能需求分析
内部评估
由于交易所项目运营在不同阶段也有不同的倾向性，因此评估重点也有所不同：
第一阶段：从 官网白皮书发布 至 开放用户注册
开放注册、开放邀请返利、开放充值所需支持新增的用户数、在线用户数
第二阶段：开放交易日
开放交易当日需支持在线用户数（行情服务需提供饱和支撑）
开放交易当日 15分钟 / 60分钟 / 24小时 的最高交易：委托量、持仓量、交易撮合量 等
第三阶段：转运维
系统每日所需支持在线用户数
系统每日所需支持交易量：委托量、持仓量、交易撮合量 等
评估说明：
在前期压测中，对以上内容的评估结果用于编写性能测试计划、方案
开放交易日 当天几乎不可能迎来注册高峰（炒过币的都懂），因此开放交易日当天的在线用户数可参考前期注册用户数以及容量规划测试结果进行服务节点增减
转运维阶段后，参考链上的重大事件（如：减产、攻击、安全事故、奖励规则修改）与日常交易量，随时对服务节点进行增减，没有必要让资源开销保持在太低的水位
不同视角对性能的期望：

视角	性能体验/需求
用户视角	行情的推送延迟（如：K线、汇率、挂单）、交易接口的延迟（下单、撤单、委托、状态更新）、其它
运维视角	数据一致性、容灾、容错、可用性、扩容
开发视角	数据一致性、订单排序、撮合效率、清算效率
币币交易	系统可承载最高持仓单量、最高委托单量、撮合性能
合约交易	系统可承载最高持仓单量、委托单量、大批量爆仓时系统强平效率、撮合与清算服务的横向扩容能力

关键需求（优先级从高至低）
可靠性：数据一致性、节点/服务/网络故障的容错能力
可用性：稳定运行时长、容灾
高性能：延迟、效率
三、测试实现
通讯协议
交易相关：HTTP（S）
市场行情：WebSocket
测试工具
需求：
易于实现高并发、可自定义 client

四、币币交易 - 测试策略
1）核心角色与业务
略
2）测试用例注意点
行情需充分确保：交易对、买/卖、深度、汇率 覆盖所有交易场景
挂单需充分确保：交易对、买/卖、价格、手数、止盈/止损 覆盖所有交易场景
行情生成时可依据时间特点，生成特殊标记的行情标记，例如价格、手数中带入时间戳信息，测试脚本即可依据接收行情时间与行情数据解析后的相减处理得到实际行情延迟，从而能够计算出每一个行情推送的响应样本数据
挂单内容需要可控，需确保覆盖订单的：部分撮合、完全撮合、不撮合 三种场景
挂单内容可依据请求发起时间，带入特殊标的时间标记，用于数据库中批量校验撮合、账户清算实际时间
……
3）测试场景设计关注点
测试场景的测试目标，包括：
略
因此，关注特定环境配置下可支持的挂单、撮合、清算 性能
大量创建不符合撮合条件的挂单、委托
大量创建符合撮合条件的挂单、委托
并发创建不符合撮合条件的挂单、委托
并发创建符合撮合条件的挂单、委托
行情消息队列行情推送延迟、送达率
行情消息队列可支撑最高的连接数
行情消息队列连接的稳定性
……
4）测试场景设计需覆盖
前期市场运营推广中的产生的异常负载场景，重点：注册登录、邀请返利结算、钱包充提币
行情剧烈波动下的负载场景，重点：撮合、委托执行效率
日常运营中，峰值负载场景
日常运营中，峰值负载场景 * n%
由于行情、汇率、交易、账户服务异常而引发的异常负载
由于程序异常、主机节点异常、网络异常、第三方接口异常 等 产生相关可靠性测试场景
可用性测试场景
……
五、币币交易 - 测试策略
1）核心角色与业务
略
2）测试用例注意点
略
3）测试场景设计关注点
测试场景的测试目标，包括：
系统可支持最高的持仓单，如：10000 单 / 1 交易服务节点
系统可支持最高的委托单，如：10000 单 / 1 交易服务节点
系统对持仓单执行市价平仓的最高处理效率，如：5000 单 / 1 秒/ 1 交易服务节点
系统对委托单执行预设委托的最高处理效率，如：5000 单 / 1 秒 / 1 交易服务节点
系统强行平仓的最高处理效率，如：5000 单 / 1秒 / 1 交易节点
系统对交易服务节点进行增加的过程中，可能产生的衰减
……
因此，关注特定环境配置下可支持的持仓单、委托单、撮合 性能：
略
4）测试场景设计需覆盖
大批量的市价开仓性能测试
大批量的市价平仓性能测试
大批量的委托开仓、创建止盈止损委托，不触发委托执行
大批量的委托开仓、创建止盈止损委托，并触发委托执行
大批量的穿仓性能测试场景：通过预先配置测试账户较低的资金余额、创建大量持仓单
大批量的爆仓性能测试场景：通过预先配置测试账户资金、创建符合要求的持仓合约量、配置爆仓风险率阈值，然后通过行情波动的模拟，实现瞬间批量爆仓测试，测试系统对5000、10000、20000 合约的系统强平处理效率
……
六、数据一致性关注点
在行情、汇率出现大量波动的前置条件下：
币币交易：关注平台资金在大批量的充币、提币、币币交易、账户内划转操作中的整体资金正确性
合约交易：关注平台资金在大量的开仓、平仓、爆仓中，整体资金的正确性，避免用户出现穿仓
……