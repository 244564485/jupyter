{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.4 (main, Nov 29 2022, 20:00:25) [GCC 9.4.0] , /home/codespace/.python/current/bin/python3 , pandas: 1.5.2\n",
      "2022-12-29 10:39:44 *****import**v1.0.1*** \n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import websocket\n",
    "import time\n",
    "import threading\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta\n",
    "import hashlib\n",
    "import hmac\n",
    "import math\n",
    "import sys\n",
    "import logging\n",
    "import os\n",
    "import getopt\n",
    "import traceback\n",
    "\n",
    "\n",
    "# pd.set_option('display.height', 1000)\n",
    "# pd.set_option('display.max_rows', 500)\t# 显示行数\n",
    "pd.set_option('display.max_columns', 500)\t# 显示列数\n",
    "pd.set_option('display.width', 1000)\t\t# 显示宽度\n",
    "\n",
    "g_worthDir = '../pkl'  # \n",
    "g_dbfile = f\"{g_worthDir}/hq.db\" # \n",
    "\n",
    "g_serverTimeadj = 10\n",
    "g_locTimeadj = 28800 # 28800 0\n",
    "\n",
    "g_name = 'backtest'\n",
    "# curDate = time.strftime(\"%Y%m%d\") # %Y%m%d %H%M%S  # %Y-%m-%d %H:%M:%S\n",
    "timestamp = int(round((time.time() ) * 1000) )\n",
    "\n",
    "serverUrl = 'http://testnet.binancefuture.com'\n",
    "# serverUrl = 'http://www.binance.com'\n",
    "# serverUrl = 'https://fapi.binance.com'\n",
    "#  #ation126@hotmail.com\n",
    "api_key    = \"fcc2838327a124367acd634323b93b1fb53d6fc66e84d679169a78adcaf1bf3e\"  # 密钥\n",
    "secret_key = \"4f58b518cecdfe9c574cd2aa9cbbea429796673d6226424bdda1f0155cd78876\"  # 私钥\n",
    "\n",
    "\n",
    "recvWindow = '5000'\n",
    "g_access = 'backtest'\n",
    "\n",
    "url = f'{serverUrl}/fapi/v1/time'\n",
    "res = requests.get(url)\n",
    "rt = json.loads(res.text)\n",
    "\n",
    "if 'code' in rt and 'msg' in rt:\n",
    "    logger.error(f'res : {res.text}')\n",
    "else:\n",
    "    serverTime = rt['serverTime']\n",
    "    g_serverTimeadj = ((rt['serverTime']- timestamp) ) //1000\n",
    "\n",
    "# df_balance = pd.DataFrame()\n",
    "# df_account = pd.DataFrame()\n",
    "# df_position = pd.DataFrame()\n",
    "# df_posirisk = pd.DataFrame()\n",
    "# df_order = pd.DataFrame()\n",
    "# df_trade = pd.DataFrame()\n",
    "\n",
    "version = \"1.0.1\"\n",
    "\n",
    "print(f\"{sys.version} , {sys.executable} , pandas: {pd.__version__}\")\n",
    "print( f'{time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(time.time()+g_locTimeadj))} *****import**v{version}*** ')\n",
    "\n",
    "# print( f'localtime :{time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(time.time()+g_locTimeadj))} ,\\n time/serverTime : {time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(serverTime//1000+g_locTimeadj))} ,\\n datetime/serverTime : {datetime.fromtimestamp(serverTime//1000+g_locTimeadj)} ,\\n {serverTime= } , {g_locTimeadj= } *****import**v{version}*** ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-29 10:39:44 *****logging***** \n"
     ]
    }
   ],
   "source": [
    "###日志 logger##20220825A######\n",
    "def make_logger(name, log_level=logging.INFO, log_file=\"log.txt\", file_mode=\"a\"): #w写 a追加\n",
    "    formatter = logging.Formatter('%(asctime)s:%(levelname)s:%(name)s:%(filename)s:%(lineno)d:%(funcName)s:%(process)s: %(message)s') # .%(msecs)03d\n",
    "    \n",
    "    logger = logging.getLogger(name)\n",
    "    if not logger.handlers:\n",
    "        logger.setLevel(level=log_level)\n",
    "        handler = logging.FileHandler(log_file, mode=file_mode)\n",
    "        handler.setLevel(level=log_level)\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "\n",
    "        handler = logging.StreamHandler(sys.stdout)\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "    return logger\n",
    "\n",
    "logger = make_logger(g_name, log_level=logging.DEBUG, log_file= f\"../logs/{g_name if ('g_name' in dir() ) else 'test' }_{ time.strftime('%Y%m%d') }.log\")\n",
    "\n",
    "print( f'{time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(time.time()+g_locTimeadj))} *****logging***** ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-29 10:39:44 *****QryServerTime***** \n"
     ]
    }
   ],
   "source": [
    "###服务器时间 QryServerTime##20220919A######\n",
    "def QryServerTime():\n",
    "    url = f'{serverUrl}/fapi/v1/time'\n",
    "    res = requests.get(url)\n",
    "    rt = json.loads(res.text)\n",
    "\n",
    "    if 'code' in rt and 'msg' in rt:\n",
    "        logger.error(f'res : {res.text}')\n",
    "    else:\n",
    "        srvTime = rt['serverTime']  \n",
    "    \n",
    "    return srvTime  \n",
    "    \n",
    "print( f'{time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(time.time()+g_locTimeadj))} *****QryServerTime***** ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-29 10:39:44 *****最新价格 ticker/price###get###QryTcikerPrice***** \n"
     ]
    }
   ],
   "source": [
    "###最新价格 ticker/price###get###QryTcikerPrice###\n",
    "def QryTcikerPrice(symbol='btcusdt'):\n",
    "\n",
    "    url = f'{serverUrl}/fapi/v1/ticker/price'\n",
    "\n",
    "    params = {\"symbol\":symbol, }\n",
    "\n",
    "    res = requests.get(url, params=params) #\n",
    "    rt = json.loads(res.text)\n",
    "\n",
    "    if 'code' in rt and 'msg' in rt :\n",
    "        logger.error(f'res : {res.text}')  \n",
    "    else :\n",
    "        logger.info(f'res : {res.text}')  #{\"symbol\":\"BTCUSDT\",\"price\":\"20137.10\",\"time\":1661961001841}\n",
    "\n",
    "print( f'{time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(time.time()+g_locTimeadj))} *****最新价格 ticker/price###get###QryTcikerPrice***** ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-29 10:39:44 *****最新标记价格和资金费率 premiumIndex###get###QryPremiumIndex***** \n"
     ]
    }
   ],
   "source": [
    "###最新标记价格和资金费率 premiumIndex###get###QryPremiumIndex###\n",
    "def QryPremiumIndex(symbol='btcusdt'):\n",
    "\n",
    "    url = f'{serverUrl}/fapi/v1/premiumIndex'\n",
    "\n",
    "    params = {\"symbol\":symbol, }\n",
    "\n",
    "    res = requests.get(url, params=params) #\n",
    "    rt = json.loads(res.text)\n",
    "\n",
    "    if 'code' in rt and 'msg' in rt :\n",
    "        logger.error(f'res : {res.text}')\n",
    "    else :\n",
    "        logger.info(f'res : {res.text}')  \n",
    "        # {\"symbol\":\"BTCUSDT\",\"markPrice\":\"20133.32973555\",\"indexPrice\":\"20133.75155317\",\"estimatedSettlePrice\":\"20056.77850121\",\"lastFundingRate\":\"-0.00194053\",\"interestRate\":\"0.00010000\",\"nextFundingTime\":1661961600000,\"time\":1661961098000}\n",
    "\n",
    "print( f'{time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(time.time()+g_locTimeadj))} *****最新标记价格和资金费率 premiumIndex###get###QryPremiumIndex***** ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now: 1.0.1 : 2022-12-29 02:39:44 *****###深度信息 depth###get###QryDepth###***** \n"
     ]
    }
   ],
   "source": [
    "###深度信息 depth###get###QryDepth###\n",
    "def QryDepth(symbol='btcusdt'):\n",
    "\n",
    "    url = f'{serverUrl}/fapi/v1/depth'\n",
    "\n",
    "    params = {\"symbol\":symbol, \"limit\":5, } \n",
    "\n",
    "    res = requests.get(url, params=params)  \n",
    "    rt = json.loads(res.text)\n",
    "\n",
    "    if 'code' in rt and 'msg' in rt :\n",
    "        logger.error(f'res : {res.text}')\n",
    "    else :\n",
    "        logger.info(f'res : {res.text}')  \n",
    "        # {\"lastUpdateId\":27532317617,\"E\":1664272323243,\"T\":1664272323241,\"bids\":[[\"20173.30\",\"4.937\"],[\"20173.00\",\"0.001\"],[\"20172.90\",\"4.228\"],[\"20172.50\",\"18.436\"],[\"20171.30\",\"14.832\"]],\"asks\":[[\"20183.40\",\"1.430\"],[\"20183.80\",\"61.862\"],[\"20184.20\",\"128.430\"],[\"20184.60\",\"71.158\"],[\"20185.00\",\"3.459\"]]}\n",
    "\n",
    "        print(f\"rt : {rt}\")\n",
    "        print(f\"rt['bids'][0][0] : {rt['bids'][0][0]}\")\n",
    "        print(f\"rt['bids'][0][0] : {rt['bids'][0][0]} , rt['asks'][0][0] : {rt['asks'][0][0]}\")\n",
    "\n",
    "print( f'Now: {version} : {time.strftime(\"%Y-%m-%d %H:%M:%S\")} *****###深度信息 depth###get###QryDepth###***** ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-29 10:39:45 *****查询行情 kline###continuousKlines***** \n"
     ]
    }
   ],
   "source": [
    "###查询行情 kline###continuousKlines###\n",
    "def continuousKlines(pair='btcusdt', contractType='PERPETUAL', interval='1m', startTime=0, endTime=0, limit=499 ):\n",
    "    \n",
    "    global serverUrl\n",
    "    url = f'{serverUrl}/fapi/v1/continuousKlines'\n",
    "\n",
    "    # pair = 'btcusdt'\n",
    "    # contractType = 'PERPETUAL'\n",
    "    # interval = '5m' #period #1m, 3m, 5m, 15m, 30m, 1h, 2h, 4h, 6h, 8h, 12h, 1d, 3d, 1w, 1M\n",
    "    # startTime = 0\n",
    "    # endTime = 0\n",
    "    # limit = 3 #499\n",
    "\n",
    "    if limit < 0 or startTime < 0 or endTime < 0 or (startTime > endTime):\n",
    "        k_df = pd.DataFrame()\n",
    "        logger.error(f'res : {{\"code\":-1130,\"msg\":\"Data sent for parameter \"limit\" or \"startTime\" or \"endTime\" is not valid.\"}}')\n",
    "        return k_df\n",
    "\n",
    "    elif limit == 0:\n",
    "        if startTime == 0 and endTime == 0:\n",
    "            k_df = pd.DataFrame()\n",
    "            logger.error(f'res : {{\"code\":-1130,\"msg\":\"Data sent for parameter \"limit\" is not valid.\"}}') \n",
    "            return k_df\n",
    "\n",
    "        elif startTime == 0:\n",
    "            params = {\"pair\":pair, \"contractType\":contractType, \"interval\":interval, \"endTime\":endTime }          \n",
    "        elif endTime == 0 :\n",
    "            params = {\"pair\":pair, \"contractType\":contractType, \"interval\":interval,\"startTime\":startTime }  \n",
    "    elif limit > 0:\n",
    "        if startTime == 0 and endTime == 0:\n",
    "            params = {\"pair\":pair, \"contractType\":contractType, \"interval\":interval, \"limit\":limit, }  \n",
    "        elif startTime == 0:\n",
    "            params = {\"pair\":pair, \"contractType\":contractType, \"interval\":interval, \"endTime\":endTime }          \n",
    "        elif endTime == 0 :\n",
    "            params = {\"pair\":pair, \"contractType\":contractType, \"interval\":interval,\"startTime\":startTime, \"limit\":limit, }   \n",
    "        elif startTime > 0 and endTime > 0:  # startTime + limit < endTime\n",
    "            params = {\"pair\":pair, \"contractType\":contractType, \"interval\":interval,\"startTime\":startTime, \"endTime\":endTime, \"limit\":limit, }   \n",
    "\n",
    "    logger.info(f'{params=}')\n",
    "    \n",
    "    res = requests.get(url, params=params)\n",
    "\n",
    "    rt = json.loads(res.text)\n",
    "\n",
    "    if 'code' in rt and 'msg' in rt:\n",
    "        k_df = pd.DataFrame()\n",
    "        logger.error(f'res : {res.text}')\n",
    "    else:\n",
    "        k_df = pd.DataFrame(rt)\n",
    "        if k_df.empty:\n",
    "            return k_df    \n",
    "        \n",
    "        k_df.columns = ['openTime','open','high','low','close','vol','closeTime','Amt','numTrade','bidVol','bidAmt','ignore'] #\n",
    "        \n",
    "        k_df['open']  = pd.to_numeric(k_df['open'] , errors='coerce', downcast='float')\n",
    "        k_df['high']  = pd.to_numeric(k_df['high'] , errors='coerce', downcast='float')\n",
    "        k_df['low']  = pd.to_numeric(k_df['low'] , errors='coerce', downcast='float')\n",
    "        k_df['close']  = pd.to_numeric(k_df['close'] , errors='coerce', downcast='float')\n",
    "        k_df['vol']  = pd.to_numeric(k_df['vol'] , errors='coerce', downcast='float')\n",
    "        k_df['Amt']  = pd.to_numeric(k_df['Amt'] , errors='coerce', downcast='float')\n",
    "        k_df['bidVol']  = pd.to_numeric(k_df['bidVol'] , errors='coerce', downcast='float')\n",
    "        k_df['bidAmt']  = pd.to_numeric(k_df['bidAmt'] , errors='coerce', downcast='float')\n",
    "        k_df['openTime']  = pd.to_numeric(k_df['openTime'] , errors='coerce', downcast='integer')\n",
    "        k_df['closeTime']  = pd.to_numeric(k_df['closeTime'] , errors='coerce', downcast='integer')\n",
    "        k_df['numTrade']  = pd.to_numeric(k_df['numTrade'] , errors='coerce', downcast='integer')\n",
    "\n",
    "        k_df['openDateTime'] = pd.to_datetime(k_df['openTime'], origin=\"1970-01-01 08:00:00\", unit=\"ms\") #, origin=\"1970-01-01 08:00:00\" , unit=\"ms\"  #debug\n",
    "        k_df['closeDateTime'] = pd.to_datetime(k_df['closeTime']//1000, origin=\"1970-01-01 08:00:00\", unit=\"s\") \n",
    "        # k_df['time'] = pd.to_datetime(int(time.time()), unit='s', unorigin=\"1970-01-01 08:00:00\")\n",
    "        \n",
    "        k_df.drop(['ignore'], axis=1, inplace=True)\n",
    "\n",
    "        k_df.sort_index(axis=1, ascending=True, inplace=True)\n",
    "\n",
    "    return k_df\n",
    "\n",
    "#权重 [1,100)  1 ; [100, 500)\t2 ; [500, 1000]\t5 ;  > 1000\t10 ;\n",
    "\n",
    "# [\n",
    "# 1661744100000,      // 开盘时间 openTime\n",
    "# \"18879.99\",         // 开盘价 open\n",
    "# \"18900.00\",         // 最高价 high\n",
    "# \"18878.98\",         // 最低价 low\n",
    "# \"18896.13\",         // 收盘价(当前K线未结束的即为最新价) close\n",
    "# \"492.363\",          // 成交量 vol\n",
    "# 1661744399999,      // 收盘时间 closeTime\n",
    "# \"9302145.66080\",    // 成交额 Amt\n",
    "# 1874,               // 成交笔数 numTrade\n",
    "# \"385.983\",          // 主动买入成交量 bidVol\n",
    "# \"7292402.33267\",    // 主动买入成交额 bidAmt\n",
    "# \"0\"                 // 请忽略该参数 ignore\n",
    "# ]\n",
    "\n",
    "# k_df = continuousKlines(pair='btcusdt', contractType='PERPETUAL', interval='1m',limit=2, startTime =1661824259000, endTime =1661824559999 ) # 2\n",
    "# k_df = continuousKlines(limit=2, endTime =1661824559999 ) # 1661824559999 ,2 \n",
    "# k_df = continuousKlines(limit=2, startTime =1661824259000, endTime =1661824559999 ) # 2\n",
    "# k_df = continuousKlines(startTime =1661824259000, endTime =1661824559999 ) # 5\n",
    "# k_df = continuousKlines(limit=2, startTime =1661824259000, ) # 2\n",
    "# k_df = continuousKlines(limit=0, startTime =0, endTime =0 ) #err 0 \n",
    "# k_df = continuousKlines(limit=-2 ) # err 0\n",
    "# k_df = continuousKlines(limit=2 ) # 2\n",
    "# print(f'{k_df}')  #11s\n",
    "\n",
    "print( f'{time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(time.time()+g_locTimeadj))} *****查询行情 kline###continuousKlines***** ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-29 10:39:45 *****查询历史行情 kline###histUKline***** \n"
     ]
    }
   ],
   "source": [
    "###查询历史行情 kline###histUKline###\n",
    "def histUKline(symbol=\"BTCUSDT\", interval=\"1m\", histDays=1, limit=998):\n",
    "    global g_locTimeadj\n",
    "\n",
    "    intervalCoef = {'m':60, 'h':60*60, 'd': 60*60*24, 'w':60*60*24*7, 'M':60*60*24*30}\n",
    "    intervalSec = int(interval[0:-1]) * intervalCoef[interval[-1] ]\n",
    "    curSec = int(time.time())\n",
    "    startSec = int(time.mktime(time.strptime(time.strftime(\"%Y%m%d\", time.localtime(time.time()-60*60*24*histDays ) ), '%Y%m%d')))\n",
    "    startSec = startSec -g_locTimeadj -1\n",
    "\n",
    "    interval_pre = interval\n",
    "    if interval_pre == '10m':\n",
    "        interval = '5m'\n",
    "        intervalSec = intervalSec//2\n",
    "\n",
    "    totalCount = math.ceil( (curSec - startSec )/intervalSec )\n",
    "    logger.info(f'{interval=}, {startSec=}, {curSec=}, {intervalSec=}, {limit=}, {intervalSec*limit=}, {totalCount=}, {histDays=}')\n",
    "\n",
    "    # ukdfHist = pd.DataFrame(columns=['tradeDate', 'openTime', 'closeTime', 'closeSec', 'open', 'close', ])\n",
    "    ukdfHist = pd.DataFrame()\n",
    "\n",
    "    count = 1\n",
    "    for Sec in range(startSec, curSec, intervalSec*limit):\n",
    "\n",
    "        print(f'{count=}:', \"continuousKlines(\", f'{symbol=}', ',', f'{interval=}', ',', f'{limit=}', ',', f'{Sec*1000+999=}', ', endTime=', f'{(Sec+intervalSec*limit-1)*1000+999}' , ' )')\n",
    "\n",
    "        ukRet = continuousKlines(pair=symbol, interval=interval, limit=limit, startTime=Sec*1000+999, endTime=(Sec+intervalSec*limit-1)*1000+999 )\n",
    "\n",
    "        kdf = pd.DataFrame([{'tradeDate': time.strftime(\"%Y%m%d\", time.localtime(rs.closeTime/1000+g_locTimeadj) ), 'openTime': time.strftime(\"%H%M%S\", time.localtime(rs.openTime/1000+g_locTimeadj) ), 'closeTime': time.strftime(\"%H%M%S\", time.localtime(rs.closeTime/1000+g_locTimeadj) ), 'closeSec': rs.closeTime//1000, 'open': rs.open, 'close': rs.close,'high': rs.high,'low': rs.low,'vol': rs.vol, 'amt': rs.Amt} for _, rs in ukRet.iterrows() ])\n",
    "\n",
    "        # ukdfHist.append(kdf)\n",
    "        ukdfHist = pd.concat([ukdfHist,kdf],ignore_index=True)\n",
    "        del kdf\n",
    "\n",
    "        count += 1\n",
    "        time.sleep(1)\n",
    "\n",
    "    logger.info(f'ukdfHist.iloc[:5,:] :\\n{ukdfHist.iloc[:5,:]}')\n",
    "    logger.info(f'ukdfHist.iloc[-5:,:] :\\n{ukdfHist.iloc[-5:,:]}')\n",
    "\n",
    "    if interval_pre == '10m':\n",
    "        interval = interval_pre\n",
    "        intervalSec = int(intervalSec*2)\n",
    "        rePeriod = '10T'\n",
    "\n",
    "        ukdfHistCp = ukdfHist.copy()\n",
    "        ukdfHistCp['dateTime'] = ukdfHistCp['closeSec'].apply(lambda x: datetime.fromtimestamp(x))\n",
    "        ukdfHistCp = ukdfHistCp.set_index(keys=['dateTime'], drop=True)\n",
    "        # ukdfHistCp = ukdfHistCp.reindex(ukdfHistCp['dateTime'].sort_values(ascending=True).index)\n",
    "\n",
    "        logger.info(f'ukdfHistCp.iloc[:5,:] :\\n{ukdfHistCp.iloc[:5,:]}')\n",
    "\n",
    "        if not ukdfHistCp.empty:\n",
    "            openSr = ukdfHistCp['open'].resample(rePeriod, label='right').first()  \n",
    "            openTimeSr = ukdfHistCp['openTime'].resample(rePeriod, label='right').first()  \n",
    "            closeSr = ukdfHistCp['close'].resample(rePeriod, label='right').last()  # resample\n",
    "            closeTimeSr = ukdfHistCp['closeTime'].resample(rePeriod, label='right').last()  \n",
    "            closeSecSr = ukdfHistCp['closeSec'].resample(rePeriod, label='right').last()  \n",
    "            tradeDateSr = ukdfHistCp['tradeDate'].resample(rePeriod, label='right').last()  \n",
    "            \n",
    "            highSr = ukdfHistCp['high'].resample(rePeriod, label='right').max()\n",
    "            lowSr = ukdfHistCp['low'].resample(rePeriod, label='right').min()\n",
    "            volSr = ukdfHistCp['vol'].resample(rePeriod, label='right').sum()\n",
    "            AmtSr = ukdfHistCp['Amt'].resample(rePeriod, label='right').sum()\n",
    "\n",
    "            ukdf = pd.concat([tradeDateSr, openTimeSr, closeTimeSr, closeSecSr,openSr, closeSr, highSr, lowSr, volSr, AmtSr], axis=1) \n",
    "            \n",
    "        ukdf.columns = ['tradeDate', 'openTime', 'closeTime', 'closeSec', 'open', 'close', 'high', 'low', 'vol', 'Amt']\n",
    "        ukdf.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        if ukdf.iloc[-1]['closeSec'] - ukdf.iloc[-2]['closeSec'] < intervalSec:\n",
    "            ukdf.drop([len(ukdf)-1],inplace=True)\n",
    "\n",
    "        # ukdf = ukdfHistCp.copy()\n",
    "        # logger.info(f'{ukdf.iloc[:5,:]=}')\n",
    "        \n",
    "        del ukdfHistCp\n",
    "\n",
    "    else:\n",
    "        ukdf = ukdfHist.copy()\n",
    "\n",
    "    del ukdfHist\n",
    "\n",
    "    ukdf['close'] = ukdf['close'].astype(float)\n",
    "    ukdf['pct'] = ukdf['close']/ukdf['close'].shift(1)-1  #涨跌幅\n",
    "    ukdf.fillna(0, inplace=True)\n",
    "\n",
    "    logger.info(f'ukdf.iloc[:5,:] :\\n{ukdf.iloc[:5,:]}')\n",
    "    logger.info(f'ukdf.iloc[-5:,:] :\\n{ukdf.iloc[-5:,:]}')\n",
    "\n",
    "    return ukdf\n",
    "\n",
    "print( f'{time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(time.time()+g_locTimeadj))} *****查询历史行情 kline###histUKline***** ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-29 10:39:45 *****查询历史行情 日kline###getDayUKline***** \n"
     ]
    }
   ],
   "source": [
    "###查询历史行情 日kline###getDayUKline###\n",
    "def getDayUKline(symbol=\"BTCUSDT\", interval=\"1m\", startDate=\"0\", endDate=\"0\", histDays=0, limit=499):\n",
    "\n",
    "    if startDate==\"0\" and endDate==\"0\" and histDays==0:\n",
    "        startSec = int(datetime.strptime(datetime.now().strftime(\"%Y%m%d\"), \"%Y%m%d\").strftime(\"%s\"))\n",
    "        endSec = int( ( datetime.fromtimestamp(startSec)+ timedelta(days=1) ).strftime(\"%s\") )\n",
    "        \n",
    "    elif startDate==\"0\" and endDate==\"0\" and abs(histDays)>0:\n",
    "        endSec = int(datetime.strptime(f\"{datetime.now().strftime('%Y%m%d')}235959\", '%Y%m%d%H%M%S').strftime(\"%s\"))        \n",
    "        startSec = int( ( datetime.fromtimestamp(endSec - 60*60*24) - timedelta(days=abs(histDays)) ).strftime(\"%s\") )\n",
    "        \n",
    "    elif int(startDate)>=20190901 and int(endDate)>int(startDate):\n",
    "        startSec = int(datetime.strptime(startDate, \"%Y%m%d\").strftime(\"%s\"))  \n",
    "        endSec = int(datetime.strptime(f\"{endDate}235959\", \"%Y%m%d%H%M%S\").strftime(\"%s\")) \n",
    "        \n",
    "    elif int(startDate)>=20190901 and endDate==\"0\" and histDays==0:\n",
    "        startSec = int(datetime.strptime(startDate, \"%Y%m%d\").strftime(\"%s\"))  \n",
    "        endSec = int(datetime.strptime(f\"{datetime.now().strftime('%Y%m%d')}235959\", '%Y%m%d%H%M%S').strftime(\"%s\")) \n",
    "        \n",
    "    elif int(startDate)>=20190901 and endDate==\"0\" and histDays>0:\n",
    "        startSec = int(datetime.strptime(startDate, \"%Y%m%d\").strftime(\"%s\"))  \n",
    "        endSec = int( ( datetime.fromtimestamp(startSec) + timedelta(days=histDays) ).strftime(\"%s\") )   \n",
    "        \n",
    "    elif startDate==\"0\" and int(endDate)>=20190901 and abs(histDays)>0:\n",
    "        endSec = int(datetime.strptime(f\"{endDate}235959\", \"%Y%m%d%H%M%S\").strftime(\"%s\"))        \n",
    "        startSec = int( ( datetime.fromtimestamp(endSec - 60*60*24) - timedelta(days=abs(histDays)) ).strftime(\"%s\") )          \n",
    "\n",
    "    else:\n",
    "        startSec = int(datetime.strptime(startDate, \"%Y%m%d\").strftime(\"%s\"))\n",
    "        endSec = int( ( datetime.fromtimestamp(startSec)+ timedelta(days=histDays) ).strftime(\"%s\") )\n",
    "\n",
    "    startSec = startSec -g_locTimeadj -1\n",
    "\n",
    "    intervalCoef = {'m':60, 'h':60*60, 'd': 60*60*24, 'w':60*60*24*7, 'M':60*60*24*30}\n",
    "    intervalSec = int(interval[0:-1]) * intervalCoef[interval[-1] ]\n",
    "\n",
    "    totalCount = math.ceil( (endSec - startSec )/intervalSec )\n",
    "    logger.info(f'{interval=}, {startSec=}, {endSec=}, {intervalSec=}, {limit=}, {intervalSec*limit=}, {totalCount=}, {histDays=}')\n",
    "\n",
    "    # ukdfHist = pd.DataFrame(columns=['tradeDate', 'openTime', 'closeTime', 'closeSec', 'open', 'close', ])\n",
    "    ukdfHist = pd.DataFrame()\n",
    "\n",
    "    count = 1\n",
    "    for Sec in range(startSec, endSec, intervalSec*limit):\n",
    "\n",
    "        stopSec = min(Sec+intervalSec*limit-1 , endSec-1)\n",
    "\n",
    "        print(f'{count=}:', \"continuousKlines(\", f'{symbol=}', ',', f'{interval=}', ',', f'{limit=}', ',', f'{Sec*1000=}', ', endTime=', f'{stopSec*1000+999}' , ' )')\n",
    "\n",
    "        ukRet = continuousKlines(pair=symbol, interval=interval, limit=limit, startTime=Sec*1000, endTime=stopSec*1000+999 )\n",
    "\n",
    "        # kdf = pd.DataFrame([{'tradeDate': time.strftime(\"%Y%m%d\", time.localtime(rs.closeTime/1000+g_locTimeadj) ), 'openTime': time.strftime(\"%H%M%S\", time.localtime(rs.openTime/1000+g_locTimeadj) ), 'closeTime': time.strftime(\"%H%M%S\", time.localtime(rs.closeTime/1000+g_locTimeadj) ), 'closeSec': rs.closeTime//1000, 'open': rs.open, 'close': rs.close,'high': rs.high,'low': rs.low,'vol': rs.vol, 'amt': rs.Amt} for _, rs in ukRet.iterrows() ])\n",
    "\n",
    "        # ukdfHist.append(kdf)\n",
    "        ukdfHist = pd.concat([ukdfHist,ukRet],ignore_index=True)\n",
    "        # del kdf\n",
    "\n",
    "        count += 1\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    logger.info(f'ukdfHist.iloc[:5,:] :\\n{ukdfHist.iloc[:5,:]}')\n",
    "    logger.info(f'ukdfHist.iloc[-5:,:] :\\n{ukdfHist.iloc[-5:,:]}')\n",
    "\n",
    "    return ukdfHist\n",
    "\n",
    "print( f'{time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(time.time()+g_locTimeadj))} *****查询历史行情 日kline###getDayUKline***** ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-29 10:39:45 *****指标 Similarity###getSimilarity***** \n"
     ]
    }
   ],
   "source": [
    "###指标 Similarity###getSimilarity###\n",
    "def getSimilarity(ukdf, wid) -> pd.DataFrame:\n",
    "    ukdfT = ukdf.pivot(index='closeTime', columns='tradeDate', values='close')\n",
    "    ukdfAmT = ukdfT.iloc[:wid].copy()\n",
    "    ukdfAmT.dropna(how='any',inplace=True)\n",
    "    ukdfAmT.reset_index(drop=True,inplace=True)\n",
    "    ukdfAmT = ukdfAmT.apply(lambda x: x.astype(float))\n",
    "\n",
    "    logger.info(f\"{ukdfAmT.corr()=}\")\n",
    "\n",
    "    df_corr = ukdfAmT.corr().iloc[:, [-1]]\n",
    "    df_corr.columns=['corr']\n",
    "    # df_corr = df_corr.reindex(df_corr['corr'].abs().sort_values(ascending=False).index)\n",
    "    df_corr = df_corr.reindex(df_corr['corr'].sort_values(ascending=False).index)\n",
    "\n",
    "    logger.info(f\"df_corr: {df_corr}\")  # corr: df_corr.iloc[1,0], data: df_corr.index[1]\n",
    "    return df_corr\n",
    "print( f'{time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(time.time()+g_locTimeadj))} *****指标 Similarity###getSimilarity***** ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QryPremiumIndex() # 最新标记价格和资金费率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.查询指定日期行情 getDayUKline() 30m\n",
    "g_symbol = \"BTCUSDT\"\n",
    "g_interval = \"30m\" #period #1m, 3m, 5m, 15m, 30m, 1h, 2h, 4h, 6h, 8h, 12h, 1d, 3d, 1w, 1M\n",
    "g_histDays = 0  # 30 10 60 84 120 \n",
    "g_limit = 998 # 1500  499 998\n",
    "\n",
    "ukdfHist = getDayUKline(symbol=g_symbol, interval=g_interval, startDate=\"20220701\") # , endDate=\"0\", histDays=0, limit=499\n",
    "# print(ukdfHist.shape)\n",
    "\n",
    "conn = sqlite3.connect(g_dbfile)\n",
    "# ##df_uk = pd.read_sql(' select * from uk30m ', conn) \n",
    "ukdfHist.to_sql('uk30m', con=conn, if_exists='append', index=False) #,\n",
    "conn.close()\n",
    "\n",
    "ukdfHist.to_pickle(f\"{g_worthDir}/uk30mdf.pkl\" )\n",
    "# ##df_uk = pd.read_pickle(f\"{g_worthDir}/uk30mdf.pkl\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.查询指定起止日期行情 getDayUKline() 4h\n",
    "g_symbol = \"BTCUSDT\"\n",
    "g_interval = \"4h\" #period #1m, 3m, 5m, 15m, 30m, 1h, 2h, 4h, 6h, 8h, 12h, 1d, 3d, 1w, 1M\n",
    "g_histDays = 0  # 30 10 60 84 120 \n",
    "g_limit = 998 # 1500  499 998\n",
    "\n",
    "ukdfHist = getDayUKline(symbol=g_symbol, interval=g_interval, startDate=\"20210101\") # , endDate=\"0\", histDays=0, limit=499\n",
    "# Amt,bidAmt,bidVol,close,closeDateTime,closeTime,high,low,numTrade,open,openDateTime,openTime,vol\n",
    "# print(ukdfHist.shape)\n",
    "\n",
    "conn = sqlite3.connect(g_dbfile)\n",
    "# ##df_uk = pd.read_sql(' select * from uk4h ', conn) \n",
    "ukdfHist.to_sql( f\"uk{g_interval}\", con=conn, if_exists='append', index=False) #,\n",
    "conn.close()\n",
    "\n",
    "ukdfHist.to_pickle(f\"{g_worthDir}/uk{g_interval}df.pkl\" )\n",
    "# ##df_uk = pd.read_pickle(f\"{g_worthDir}/uk30mdf.pkl\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.查询指定天数行情 histUKline()  4h\n",
    "symbol = \"BTCUSDT\"\n",
    "interval = \"4h\" #period #1m, 3m, 5m, 15m, 30m, 1h, 2h, 4h, 6h, 8h, 12h, 1d, 3d, 1w, 1M\n",
    "histDays = 2  # 30 10 60 84 120 \n",
    "limit = 998 # 1500  499 998\n",
    "wid = 42\n",
    "\n",
    "ukdf = histUKline(interval=interval, histDays=histDays, limit=498)\n",
    "print(ukdf.shape)\n",
    "# print(ukdf)\n",
    "# print(f'ukdf.iloc[:5,:] :\\n{ukdf.iloc[:5,:]}')\n",
    "# print(f'ukdf.iloc[-5:,:] :\\n{ukdf.iloc[-5:,:]}')\n",
    "\n",
    "# ukRet = continuousKlines(pair=symbol, interval=\"5m\", limit=3 )\n",
    "# kdf = pd.DataFrame([{'tradeDate': time.strftime(\"%Y%m%d\", time.localtime(rs.closeTime/1000+g_locTimeadj) ), 'openTime': time.strftime(\"%H%M%S\", time.localtime(rs.openTime/1000+g_locTimeadj) ), 'closeTime': time.strftime(\"%H%M%S\", time.localtime(rs.closeTime/1000+g_locTimeadj) ), 'closeSec': rs.closeTime//1000, 'open': rs.open, 'close': rs.close} for _, rs in ukRet.iterrows() ])\n",
    "# print(kdf)\n",
    "\n",
    "# t1 = threading.Thread(target=wssApp, args=(), kwargs={}, )\n",
    "# t1.start()\n",
    "# stop_thread(thread)\n",
    "\n",
    "conn = sqlite3.connect(g_dbfile)\n",
    "# ##df_uk = pd.read_sql(' select * from uk4h ', conn) \n",
    "ukdf.to_sql('uk4h', con=conn, if_exists='append', index=False) #,\n",
    "conn.close()\n",
    "\n",
    "ukdf.to_pickle(f\"{g_worthDir}/uk4hdf.pkl\" )\n",
    "# ##df_uk = pd.read_pickle(f\"{g_worthDir}/uk4hdf.pkl\" )\n",
    "\n",
    "# nohup python3 -u main.py -n testStrategy -s 8808 -c 29090 -X BTCUSDT -p 10m -w 42 -d 84 -t 1000000  >> log.txt 2>&1  &\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 查询指定天数行情 histUKline() 5m\n",
    "symbol = \"BTCUSDT\"\n",
    "interval = \"5m\" #period #1m, 3m, 5m, 15m, 30m, 1h, 2h, 4h, 6h, 8h, 12h, 1d, 3d, 1w, 1M\n",
    "histDays = 30  # 30 10 60 84 120 \n",
    "limit = 998 # 1500  499 998\n",
    "wid = 42\n",
    "\n",
    "ukdf = histUKline(interval=interval, histDays=histDays, limit=498)\n",
    "print(ukdf.shape)\n",
    "# print(ukdf)\n",
    "print(f'ukdf.iloc[:5,:] :\\n{ukdf.iloc[:5,:]}')\n",
    "print(f'ukdf.iloc[-5:,:] :\\n{ukdf.iloc[-5:,:]}')\n",
    "\n",
    "\n",
    "# conn = sqlite3.connect(dbfile)\n",
    "# ##df_uk = pd.read_sql(' select * from uk4h ', conn) \n",
    "# ukdf.to_sql('uk4h', con=conn, if_exists='append', index=False) #,\n",
    "# conn.close()\n",
    "\n",
    "ukdf.to_pickle(f\"{g_worthDir}/uk5mdf.pkl\" )\n",
    "# ##df_uk = pd.read_pickle(f\"{g_worthDir}/uk5mdf.pkl\" )\n",
    "\n",
    "# nohup python3 -u main.py -n testStrategy -s 8808 -c 29090 -X BTCUSDT -p 10m -w 42 -d 84 -t 1000000  >> log.txt 2>&1  &\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 查询指定年份行情 getDayUKline() \n",
    "g_symbol = \"BTCUSDT\"\n",
    "g_interval = \"5m\" #period #1m, 3m, 5m, 15m, 30m, 1h, 2h, 4h, 6h, 8h, 12h, 1d, 3d, 1w, 1M\n",
    "g_histDays = 0  # 30 10 60 84 120 \n",
    "g_histYear = '2021' # 2021 2022\n",
    "g_limit = 998 # 1500  499 998\n",
    "\n",
    "ukdfHist = getDayUKline(symbol=g_symbol, interval=g_interval, startDate=f\"{g_histYear}0101\" ) # , endDate=\"0\", histDays=0, limit=499\n",
    "# Amt,bidAmt,bidVol,close,closeDateTime,closeTime,high,low,numTrade,open,openDateTime,openTime,vol\n",
    "# print(ukdfHist.shape)\n",
    "\n",
    "conn = sqlite3.connect(g_dbfile)\n",
    "# ##df_uk = pd.read_sql(' select * from uk4h ', conn) \n",
    "ukdfHist.to_sql( f\"uk{g_interval}_{g_histYear}\", con=conn, if_exists='append', index=False) #,\n",
    "conn.close()\n",
    "\n",
    "ukdfHist.to_pickle(f\"{g_worthDir}/uk{g_interval}_{g_histYear}df.pkl\" )\n",
    "# ##df_uk = pd.read_pickle(f\"{g_worthDir}/uk30mdf.pkl\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 补全/查询指定日期行情 getDayUKline() \n",
    "g_symbol = \"BTCUSDT\"\n",
    "g_interval = \"5m\" # period #1m, 3m, 5m, 15m, 30m, 1h, 2h, 4h, 6h, 8h, 12h, 1d, 3d, 1w, 1M\n",
    "g_histDays = 0  # 30 10 60 84 120 \n",
    "g_limit = 998 # 1500  499 998\n",
    "\n",
    "df_uk = pd.DataFrame()\n",
    "startDate = 0\n",
    "\n",
    "df_uk = pd.read_pickle(f\"{g_worthDir}/uk{g_interval}df.pkl\" )\n",
    "startDate = df_uk.tradeDate.iloc[-1]\n",
    "\n",
    "print(f\"{df_uk.shape }\")\n",
    "print(f\"df_uk.head(2): \\n{df_uk.head(2) }\")\n",
    "print(f\"df_uk.tail(2): \\n{df_uk.tail(2) }\")\n",
    "\n",
    "ukdfHist = getDayUKline(symbol=g_symbol, interval=g_interval, startDate=startDate) # , endDate=\"0\", histDays=0, limit=499\n",
    "# print(ukdfHist.shape)\n",
    "\n",
    "kdf = pd.DataFrame([{'tradeDate': time.strftime(\"%Y%m%d\", time.localtime(rs.closeTime/1000+g_locTimeadj) ), 'openTime': time.strftime(\"%H%M%S\", time.localtime(rs.openTime/1000+g_locTimeadj) ), 'closeTime': time.strftime(\"%H%M%S\", time.localtime(rs.closeTime/1000+g_locTimeadj) ), 'closeSec': rs.closeTime//1000, 'open': rs.open, 'close': rs.close,'high': rs.high,'low': rs.low,'vol': rs.vol, 'amt': rs.Amt} for _, rs in ukdfHist.iterrows() ])\n",
    "\n",
    "kdf['close'] = kdf['close'].astype(float)\n",
    "kdf['pct'] = kdf['close']/kdf['close'].shift(1)-1  #涨跌幅\n",
    "kdf.fillna(0, inplace=True)\n",
    "\n",
    "# df_uk.sort_values(by='closeSec') # 按 closeSec列数据升序排列  # 降序 , ascending=False\n",
    "df_uk = pd.concat([df_uk,kdf],ignore_index=True)\n",
    "df_uk.drop_duplicates(subset=[\"closeSec\"], keep=\"last\", inplace=True, ignore_index=True)\n",
    "df_uk['pct'] = df_uk['close']/df_uk['close'].shift(1)-1  #涨跌幅\n",
    "\n",
    "# conn = sqlite3.connect(g_dbfile)\n",
    "# # ##df_uk = pd.read_sql(' select * from uk5m ', conn) \n",
    "# ukdfHist.to_sql('uk5m', con=conn, if_exists='append', index=False) #,\n",
    "# conn.close()\n",
    "\n",
    "df_uk.to_pickle(f\"{g_worthDir}/uk{g_interval}df.pkl\" )\n",
    "# ##df_uk = pd.read_pickle(f\"{g_worthDir}/uk5mdf.pkl\" )\n",
    "\n",
    "print(f\"{df_uk.shape }\")\n",
    "print(f\"df_uk.head(2): \\n{df_uk.head(2) }\")\n",
    "print(f\"df_uk.tail(2): \\n{df_uk.tail(2) }\")\n",
    "\n",
    "df1 = df_uk[df_uk.tradeDate == startDate]\n",
    "print(f\"{df1.shape }\")\n",
    "print(f\"df1.head(2): \\n{df1.head(2) }\")\n",
    "print(f\"df1.tail(2): \\n{df1.tail(2) }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 合并指定日期行情 getDayUKline() uk5m_2021df\n",
    "\n",
    "uk5mFolder = f\"/workspaces/jupyter/tmp\" \n",
    "# /workspaces/jupyter/tmp/uk5m_2021df.pkl /workspaces/backup/bigdata\n",
    "uk5mFile = f\"{uk5mFolder}/uk5m_2021df.pkl\"\n",
    "df_uk = pd.read_pickle(f\"{uk5mFile}\" )\n",
    "\n",
    "# uk_df = pd.DataFrame([{'tradeDate': time.strftime(\"%Y%m%d\", time.localtime(rs.closeTime/1000+g_locTimeadj) ), 'openTime': time.strftime(\"%H%M%S\", time.localtime(rs.openTime/1000+g_locTimeadj) ), 'closeTime': time.strftime(\"%H%M%S\", time.localtime(rs.closeTime/1000+g_locTimeadj) ), 'closeSec': rs.closeTime//1000, 'open': rs.open, 'close': rs.close,'high': rs.high,'low': rs.low,'vol': rs.vol, 'amt': rs.Amt} for _, rs in df_uk.iterrows() ])\n",
    "\n",
    "kdf = pd.read_pickle(f\"{g_worthDir}/uk5mdf.pkl\" )\n",
    "\n",
    "# df_uk.sort_values(by='closeSec') # 按 closeSec列数据升序排列  # 降序 , ascending=False\n",
    "df_uk = pd.concat([df_uk,kdf],ignore_index=True)\n",
    "df_uk.drop_duplicates(subset=[\"closeSec\"], keep=\"last\", inplace=True, ignore_index=True)\n",
    "kdf['close'] = kdf['close'].astype(float)\n",
    "df_uk['pct'] = df_uk['close']/df_uk['close'].shift(1)-1  #涨跌幅\n",
    "\n",
    "df_uk.to_pickle(f\"{uk5mFile}\" )\n",
    "\n",
    "print(f\"{df_uk.shape }\")\n",
    "print(f\"df_uk.head(2): \\n{df_uk.head(2) }\")\n",
    "print(f\"df_uk.tail(2): \\n{df_uk.tail(2) }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18861, 11)\n",
      "df_uk.head(2): \n",
      "  tradeDate openTime closeTime    closeSec     open    close     high      low        vol           amt       pct\n",
      "0  20221024   000000    000459  1666541099  19335.0  19335.0  19335.0  19200.2  18.882999  3.636677e+05       NaN\n",
      "1  20221024   000500    000959  1666541399  19334.0  19339.0  19339.0  19201.0  53.950001  1.041028e+06  0.000207\n",
      "df_uk.tail(2): \n",
      "      tradeDate openTime closeTime    closeSec     open    close     high      low         vol           amt       pct\n",
      "18859  20221228   113500    113959  1672198799  16824.8  16658.8  16824.8  16647.0  468.325989  7.811034e+06  0.000228\n",
      "18860  20221228   114000    114459  1672199099  16652.5  16828.8  16828.8  16646.2  205.018997  3.424889e+06  0.010205\n",
      "<class 'str'>, startDate = '20221228'\n"
     ]
    }
   ],
   "source": [
    "# print( f\"{ ukdfHist.head(2) }\" )\n",
    "\n",
    "# print( f\"{ ukdfHist.tail(2) }\" )\n",
    "\n",
    "# ukdfHist.head(2)\n",
    "# ukdfHist.tail(2)\n",
    "\n",
    "# df_uk = pd.read_pickle(f\"{g_worthDir}/uk30mdf.pkl\" )\n",
    "# df_uk.close.tail(2)\n",
    "\n",
    "# df_uk = pd.read_pickle(f\"{g_worthDir}/uk4hdf.pkl\" )\n",
    "# df_uk.closeDateTime.tail(2)\n",
    "\n",
    "df_uk = pd.read_pickle(f\"{g_worthDir}/uk5mdf.pkl\" )\n",
    "# df_uk.closeDateTime.tail(2)\n",
    "\n",
    "print(f\"{df_uk.shape }\")\n",
    "print(f\"df_uk.head(2): \\n{df_uk.head(2) }\")\n",
    "print(f\"df_uk.tail(2): \\n{df_uk.tail(2) }\")\n",
    "\n",
    "startDate = df_uk.tradeDate.iloc[-1]\n",
    "\n",
    "print(f\"{type(startDate)}, {startDate = }\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
